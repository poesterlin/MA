@article{elicitation,
   abstract = {Gesture elicitation studies represent a popular and resourceful method in HCI to inform the design of intuitive gesture commands, reflective of end-users' behavior, for controlling all kinds of interactive devices, applications, and systems. In the last ten years, an impressive body of work has been published on this topic, disseminating useful design knowledge regarding users' preferences for finger, hand, wrist, arm, head, leg, foot, and whole-body gestures. In this paper, we deliver a systematic literature review of this large body of work by summarizing the characteristics and findings ofN=216gesture elicitation studies subsuming 5,458 participants, 3,625 referents, and 148,340 elicited gestures. We highlight the descriptive, comparative, and generative virtues of our examination to provide practitioners with an effective method to (i) understand how new gesture elicitation studies position in the literature; (ii) compare studies from different authors; and (iii) identify opportunities for new research.},
   author = {Santiago Villarreal-Narvaez and Jean Vanderdonckt and Radu Daniel Vatavu and Jacob O. Wobbrock},
   doi = {10.1145/3357236.3395511},
   journal = {DIS 2020 - Proceedings of the 2020 ACM Designing Interactive Systems Conference},
   keywords = {Gesture elicitation,Survey,Systematic literature review},
   month = {7},
   pages = {855-872},
   publisher = {Association for Computing Machinery, Inc},
   title = {A systematic review of gesture elicitation studies: What can we learn from 216 studies?},
   year = {2020},
}
@misc{Magnopus,
   author = {Magnopus},
   title = {Elixir für Oculus Quest 2 | Oculus},
   url = {https://www.oculus.com/experiences/quest/3793077684043441/?locale=de_DE},
}
@misc{Ultraleap,
   title = {World-leading Hand Tracking: Small. Fast. Accurate. | Ultraleap},
   url = {https://www.ultraleap.com/tracking/},
}
@misc{github,
   author = {jorgejgnz},
   title = {jorgejgnz/HandTrackingGestureRecorder: Unity script to record any gesture with your own hands},
   url = {https://github.com/jorgejgnz/HandTrackingGestureRecorder#readme},
   year = {2021},
}
@article{Zhang2017,
abstract = {In this paper, we present a double hand-gesture interaction (DHGI) method for walk-through in VR environment with an Oculus Rift headset and Leap Motion function. The user can control the avatar (first-person view) to move (walk/run) forward or backward by turning the user's left palm upward or downward, and by turning the avatar to the left or right with the right thumb pointing toward either direction. Compared with the results of the joystick input device and portal method using Oculus Rift Touches, the objective and subjective findings of this study indicate that DHGI is intuitive, easy to learn, easy to use, and causes low fatigue. Moreover, the user feedback shows that DHGI significantly improves immersion and reduces the sense of motion sickness in VR.},
author = {Zhang, Fan and Chu, Shaowei and Pan, Ruifang and Ji, Naye and Xi, Lian},
doi = {10.1109/ICIS.2017.7960051},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - Double hand-gesture interaction for walk-through in VR environment.pdf:pdf},
journal = {Proceedings - 16th IEEE/ACIS International Conference on Computer and Information Science, ICIS 2017},
keywords = {Double Hand-gesture Interaction (DHGI),Leap Motion,Virtual Reality,Walk-through},
month = {jun},
pages = {539--544},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Double hand-gesture interaction for walk-through in VR environment}},
year = {2017}
}
@article{Bozgeyikli2016a,
abstract = {Virtual reality (VR) has been used as an effective tool for training individuals with autism spectrum disorder (ASD). Recently there have been an increase in the number of applications developed for this purpose. One of the most important aspects of these applications is locomotion, which is an essential form of human computer interaction. Locomotion in VR has a direct effect on many aspects of user experience such as enjoyment, frustration, tiredness, motion sickness and presence. There have been many locomotion techniques proposed for VR. Most of them were designed and evaluated for neurotypical users. On the other hand, for individuals with ASD there isn't any study to our knowledge that focuses on locomotion techniques and their evaluation. In this study, eight locomotion techniques were implemented in an immersive virtual reality test environment. These eight VR locomotion techniques may be categorized as follows: three commonly used locomotion techniques (redirected walking, walk-in-place and joystick controller), two unexplored locomotion techniques (stepper machine and point \& teleport) and three locomotion techniques that were selected and designed for individuals with ASD based on their common characteristics (flying, flapping and trackball controller). A user study was performed with 12 high functioning individuals with ASD. Results indicated that joystick and point \& teleport techniques provided the most comfortable use for individuals with ASD, followed by walk in place and trackball. On the other hand, flying and hand flapping did not provide comfortable use for individuals with ASD.},
address = {New York, NY, USA},
author = {Bozgeyikli, Evren and Raij, Andrew and Katkoori, Srinivas and Dubey, Rajiv},
doi = {10.1145/2983310},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bozgeyikli et al. - 2016 - Locomotion in Virtual Reality for Individuals with Autism Spectrum Disorder.pdf:pdf},
journal = {Proceedings of the 2016 Symposium on Spatial User Interaction},
keywords = {Autism,Human Computer Interaction,Locomotion,Virtual Reality},
publisher = {ACM},
title = {{Locomotion in Virtual Reality for Individuals with Autism Spectrum Disorder}},
url = {http://dx.doi.org/10.1145/2983310.2985763},
year = {2016}
}
@article{bozgeyikli,
abstract = {With the increasing popularity of virtual reality (VR) and new devices getting available with relatively lower costs, more and more video games have been developed recently. Most of these games use first person interaction techniques since it is more natural for Head Mounted Displays (HMDs). One of the most widely used interaction technique in VR video games is locomotion that is used to move user's viewpoint in virtual environments. Locomotion is an important component of video games since it can have a strong influence on user experience. In this study, a new locomotion technique we called "Point \& Teleport" is described and compared with two commonly used VR locomotion techniques of walk-in-place and joystick. In this technique, users simply point where they want to be in virtual world and they are teleported to that position. As a major advantage, it is not expected to introduce motion sickness since it does not involve any visible translational motion. In this study, two VR experiments were designed and performed to analyze the Point \& Teleport technique. In the first experiment, Point \& Teleport was compared with walkin-place and joystick locomotion techniques. In the second experiment, a direction component was added to the Point \& Teleport technique so that the users could specify their desired orientation as well. 16 users took part in both experiments. Results indicated that Point \& Teleport is a fun and user friendly locomotion method whereas the additional direction component degraded the user experience.},
author = {Bozgeyikli, Evren and Raij, Andrew and Katkoori, Srinivas and Dubey, Rajiv},
doi = {10.1145/2967934.2968105},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bozgeyikli et al. - 2016 - Point \& Teleport locomotion technique for virtual reality(3).pdf:pdf},
journal = {CHI PLAY 2016 - Proceedings of the 2016 Annual Symposium on Computer-Human Interaction in Play},
keywords = {Locomotion,Teleportation,Virtual reality},
month = {oct},
pages = {205--216},
publisher = {Association for Computing Machinery, Inc},
title = {{Point \& Teleport locomotion technique for virtual reality}},
year = {2016}
}
@article{Caggianese,
abstract = {Virtual reality has achieved significant popularity in recent years, and allowing users to move freely within an immersive virtual world has become an important factor critical to realize. The user...},
author = {Caggianese, Giuseppe and Capece, Nicola and Erra, Ugo and Gallo, Luigi and Rinaldi, Michele},
doi = {10.1080/10447318.2020.1785151},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Caggianese et al. - 2020 - Freehand-Steering Locomotion Techniques for Immersive Virtual Environments A Comparative Evaluation.pdf:pdf},
journal = {https://doi.org/10.1080/10447318.2020.1785151},
pages = {1734--1755},
publisher = {Taylor \& Francis},
title = {{Freehand-Steering Locomotion Techniques for Immersive Virtual Environments: A Comparative Evaluation}},
url = {https://www.tandfonline.com/doi/abs/10.1080/10447318.2020.1785151},
year = {2020}
}
@article{Tcha-Tokey,
abstract = {Most of the models of User eXperience (UX) in Immersive Virtual Environment (IVE) are partial due to the components and the measuring methods they suggest. We have presented in a previous work a holistic UX in IVE model, combining key components and influencing factors from the most common fields of Virtual Reality (education, entertainment and edutainment). We do not doubt that the best way to measure the UX in IVEs is to gather and compare results from the appropriate subjective methods with the appropriate objective methods. Nevertheless, in this paper, we chose to focus only on the questionnaire method. Indeed, most of components can be measured through questionnaires. The objective of this paper is to rely on the components of our UX model to select appropriate existing questionnaires and finally choose the more suitable items to create our own mixed questionnaire. First, this paper reviews the questionnaires chosen to create our own. Finally, it proposes an elaboration of the final questionnaire. CCS Concepts • Software and its engineering➝Virtual worlds training simulations • Computing methodologies➝Virtual reality.},
address = {New York, NY, USA},
author = {Tcha-Tokey, Katy and Loup-Escande, Emilie and Christmann, Olivier and Richir, Simon},
doi = {10.1145/2927929},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tcha-Tokey et al. - Unknown - A Questionnaire to Measure the User Experience in Immersive Virtual Environments.pdf:pdf},
journal = {Proceedings of the 2016 Virtual Reality International Conference},
keywords = {Model,Non-Instrumental Measures,Questionnaire,Subjective Methods,User Experience,Virtual Environment},
publisher = {ACM},
title = {{A Questionnaire to Measure the User Experience in Immersive Virtual Environments}},
url = {http://dx.doi.org/10.1145/2927929.2927955}
}
@article{Jacob2008,
abstract = {We are in the midst of an explosion of emerging human-computer interaction techniques that redefine our understanding of both computers and interaction. We propose the notion of Reality-Based Interaction (RBI) as a unifying concept that ties together a large subset of these emerging interaction styles. Based on this concept of RBI, we provide a framework that can be used to understand, compare, and relate current paths of recent HCI research as well as to analyze specific interaction designs. We believe that viewing interaction through the lens of RBI provides insights for design and uncovers gaps or opportunities for future research.},
address = {New York, New York, USA},
author = {Jacob, Robert J K and Girouard, Audrey and Hirshfield, Leanne M and Horn, Michael S and Shaer, Orit and Solovey, Erin Treacy and Zigelbaum, Jamie},
doi = {10.1145/1357054},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jacob et al. - 2008 - Reality-Based Interaction A Framework for Post-WIMP Interfaces.pdf:pdf},
journal = {Proceeding of the twenty-sixth annual CHI conference on Human factors in computing systems  - CHI '08},
keywords = {Author Keywords Reality-Based Interaction,context-aware,interaction styles,multimodal,next-generation,post-WIMP interfaces ACM Classification Keywords H52 [Information Interfaces and Presentation]: User Interfaces H12 [Models and Principles]: User/Machine Systems-human factors;,tangible interfaces,ubiquitous computing,virtual reality},
publisher = {ACM Press},
title = {{Reality-Based Interaction: A Framework for Post-WIMP Interfaces}},
year = {2008}
}
@misc{WaWizTelePath,
title = {{Introducing Next Generation Telepath VR Movement Features | by Aldin | Aldin Blog | Medium}},
url = {https://medium.com/aldin-dynamics/introducing-next-generation-telepath-vr-movement-features-6417a7e0ff49},
urldate = {2021-07-07}
}
@misc{Aladin,
title = {{Aldin Blog – Medium}},
url = {https://medium.com/aldin-dynamics},
urldate = {2021-07-07}
}
@misc{WaWizBlog,
title = {{Natural Magic is Now live on the Oculus Store and Steam | by Aldin | Aldin Blog | Jul, 2021 | Medium}},
url = {https://medium.com/aldin-dynamics/natural-magic-is-now-live-on-the-oculus-store-and-steam-7a8115f35e1e},
urldate = {2021-07-07}
}
@misc{WaWizOculus,
title = {{Waltz of the Wizard: Natural Magic f{\"{u}}r Oculus Quest | Oculus}},
url = {https://www.oculus.com/experiences/quest/2280285932034855/},
urldate = {2021-07-07}
}
@misc{VacSimBlog,
title = {{How to Hands: A Developer Deep Dive on Hand Tracking in Vacation Simulator | Owlchemy Labs}},
url = {https://owlchemylabs.com/how-to-hands-a-developer-deep-dive-on-hand-tracking-in-vacation-simulator/},
urldate = {2021-07-07}
}
@misc{VacSimOculus,
title = {{Vacation Simulator f{\"{u}}r Oculus Quest | Oculus}},
url = {https://www.oculus.com/experiences/quest/2393300320759737/},
urldate = {2021-07-06}
}
@article{Abtahi,
abstract = {Figure 1: Left) Average human-size avatar walking in a large virtual city. Middle) Ground-Level Scaling technique used to achieve a 10x speed gain. Right) Eye-Level Scaling used to achieve a 10x speed gain, while maintaining a street-level view. ABSTRACT Advances in tracking technology and wireless headsets enable walking as a means of locomotion in Virtual Reality. When exploring virtual environments larger than room-scale, it is often desirable to increase users' perceived walking speed, for which we investigate three methods. (1) Ground-Level Scaling increases users' avatar size, allowing them to walk farther. (2) Eye-Level Scaling enables users to walk through a World in Miniature, while maintaining a street-level view. (3) Seven-League Boots amplifies users' movements along their walking path. We conduct a study comparing these methods and find that users feel most embodied using Ground-Level Scaling and consequently increase their stride length. Using Seven-League Boots, unlike the other two methods, diminishes positional accuracy at high gains, and users modify their walking behavior to compensate for the lack of control. We conclude with a discussion on each technique's strength and weaknesses and the types of situation they might be appropriate for.},
author = {Abtahi, Parastoo and Gonzalez-Franco, Mar and Ofek, Eyal and Steed, Anthony},
doi = {10.1145/3290605.3300752},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abtahi et al. - Unknown - I'm a Giant Walking in Large Virtual Environments at High Speed Gains.pdf:pdf},
isbn = {9781450359702},
keywords = {CCS CONCEPTS • Human-centered computing → User stu,KEYWORDS Virtual Reality, Locomotion, Walking Spee,Virtual reality},
title = {{I'm a Giant: Walking in Large Virtual Environments at High Speed Gains}},
url = {https://doi.org/10.1145/3290605.3300752}
}
@techreport{Lin,
abstract = {Figure 1: In our experiment, participants complete block stacking puzzles in virtual reality (left), controlling their avatar's hands either with tracked gloves (middle, left) or with touch controllers (middle, right). The avatar's hands are varied to fit the participant's hands in size or to be 25% larger or smaller (right). ABSTRACT Most commercial virtual reality applications with self avatars provide users with a "one-size fits all" avatar. While the height of this body may be scaled to the user's height, other body proportions, such as limb length and hand size, are rarely customized to fit an individual user. Prior research has shown that mismatches between users' avatars and their actual bodies can affect size perception and feelings of body ownership. In this paper, we consider how concepts related to the virtual hand illusion, user experience, and task efficiency are influenced by variations between the size of a user's actual hand and their avatar's hand. We also consider how using a tracked controller or tracked gestures affect these concepts. We conducted a 2x3 within-subjects study (n=20), with two levels of input modality: using tracked finger motion vs. a hand-held controller (Glove vs. Controller), and three levels of hand scaling (Small, Fit, and Large). Participants completed 2 block-assembly trials for each condition (for a total of 12 trials). Time, mistakes, and a user experience survey were recorded for each trial. Participants experienced stronger feelings of ownership and realism in the Glove condition. Efficiency was higher in the Controller condition and supported by play data of more time spent, blocks grabbed, and blocks dropped in the Glove condition. We did not find enough evidence for a change in agency and the intensity of the virtual hand illusion depending on hand size. Over half of the * participants indicated preferring the Glove condition over the Controller condition, mentioning fun and efficiency as factors in their choices. Preferences on hand scaling were mixed but often attributed to efficiency. Participants liked the appearance of their virtual hand more while using the Fit instead of Large hands. Several interaction effects were observed between input modality and hand scaling, for example, for smaller hands, tracked hands evoked stronger feelings of ownership compared to using a controller. Our results show that the virtual hand illusion is stronger when participants are able to control a hand directly rather than with a hand-held device, and that the virtual reality task must first be considered to determine which modality and hand size are the most applicable.},
author = {Lin, Lorraine and Normoyle, Aline and Adkins, Alexandra and Sun, Yu and Robb, Andrew and ||, Yuting Ye and Luca, Massimiliano Di and Org, Sophie J ¨},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin et al. - Unknown - The Effect of Hand Size and Interaction Modality on the Virtual Hand Illusion.pdf:pdf},
keywords = {Computing methodologies-Perception,Human-centered computing-Interaction design,Index Terms: Human-centered computing-Virtual real},
title = {{The Effect of Hand Size and Interaction Modality on the Virtual Hand Illusion}},
url = {https://www.youtube.com/watch?v=Xx21y9eJq1U}
}
@misc{Beauchamp,
author = {Beauchamp, Daniel},
title = {{Locomotion in VR has just been solved. Pack it in, folks. | Twitter}},
url = {https://twitter.com/pushmatrix/status/1227302127862734849},
urldate = {2021-06-20}
}
@article{Koelsch,
abstract = {Biomechanics determines the physical range in which humans can move their bodies. Human factors research delineates a subspace in which humans can operate without experiencing musculoskeletal strain, fatigue or discomfort. We claim that there is an even tighter space which we call the comfort zone. It is defined as the range of postures adopted voluntarily — despite the availability of other postures. We introduce a measurable, objective foundation for comfort, which was previously assumed equivalent to the absence of discomfort, a subjective quantity. Interfaces designed outside a user's comfort zone can prompt the adoption of alternative use patterns, which are often less favorable because they trade off the unnoticeable potential of injury for comfort. Designing interfaces within the limits of comfort zones can avert these risks.},
author = {K{\"{o}}lsch, Mathias and Beall, Andrew C. and Turk, Matthew},
doi = {10.1177/154193120304700413},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/K{\"{o}}lsch, Beall, Turk - 2003 - An Objective Measure for Postural Comfort.pdf:pdf},
issn = {2169-5067},
journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
month = {oct},
number = {4},
pages = {725--728},
publisher = {SAGE Publications},
title = {{An Objective Measure for Postural Comfort}},
url = {https://journals.sagepub.com/doi/abs/10.1177/154193120304700413},
volume = {47},
year = {2003}
}
@article{Royden,
abstract = {When an observer moves through an environment containing stationary and moving objects, he or she must be able to determine which objects are moving relative to the others in order to navigate successfully and avoid collisions. We investigated whether image speed can be used as a cue to detect a moving object in the scene. Our results show that image speed can be used to detect moving objects as long as the object is moving sufficiently faster or slower than it would if it were part of the stationary scene. {\textcopyright} 2012 Elsevier Ltd.},
author = {Royden, Constance S. and Moore, Kathleen D.},
doi = {10.1016/j.visres.2012.02.006},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Royden, Moore - 2012 - Use of speed cues in the detection of moving objects by moving observers.pdf:pdf},
issn = {00426989},
journal = {Vision Research},
keywords = {Heading,Motion,Moving object detection,Optic flow},
month = {apr},
pages = {17--24},
pmid = {22406544},
publisher = {Pergamon},
title = {{Use of speed cues in the detection of moving objects by moving observers}},
volume = {59},
year = {2012}
}
@article{MartinUsoh1995,
author = {{Martin Usoh}, Mel Slater and Steed, Anthony},
doi = {10.1145/210079.210084},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Martin Usoh, Steed - 1995 - Taking Steps The Influence of a Walking Technique on Presence in Virtual Reality.pdf:pdf},
issn = {15577325},
journal = {ACM Transactions on Computer-Human Interaction (TOCHI)},
number = {3},
pages = {201--219},
title = {{Taking Steps: The Influence of a Walking Technique on Presence in Virtual Reality}},
volume = {2},
year = {1995}
}
@inproceedings{Bowman,
abstract = {We present a categorization of techniques for first-person motion control, or travel, through immersive virtual environments, as well as a framework for evaluating the quality of different techniques for specific virtual environment tasks. We conduct three quantitative experiments within this framework: a comparison of different techniques for moving directly to a target object varying in size and distance, a comparison of different techniques for moving relative to a reference object, and a comparison of different motion techniques and their resulting sense of 'disorientation' in the user. Results indicate that 'pointing' techniques are advantageous relative to 'gaze-directed' steering techniques for a relative motion task, and that motion techniques which instantly teleport users to new locations are correlated with increased user disorientation.},
author = {Bowman, Doug A. and Koller, David and Hodges, Larry F.},
booktitle = {Proceedings - Virtual Reality Annual International Symposium},
doi = {10.1109/vrais.1997.583043},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bowman, Koller, Hodges - 1997 - Travel in immersive virtual environments an evaluation of viewpoint motion control techniques.pdf:pdf},
pages = {45--52},
publisher = {IEEE},
title = {{Travel in immersive virtual environments: an evaluation of viewpoint motion control techniques}},
year = {1997}
}
@article{VanBeers1999,
abstract = {To localize one's hand, i.e., to find out its position with respect to the body, humans may use proprioceptive information or visual information or both. It is still not known how the CNS combines simultaneous proprioceptive and visual information. In this study, we investigate in what position in a horizontal plane a hand is localized on the basis of simultaneous proprioceptive and visual information and compare this to the positions in which it is localized on the basis of proprioception only and vision only. Seated at a table, subjects matched target positions on the table top with their unseen left hand under the table. The experiment consisted of three series. In each of these series, the target positions were presented in three conditions: by vision only, by proprioception only, or by both vision and proprioception. In one of the three series, the visual information was veridical. In the other two, it was modified by prisms that displaced the visual field to the left and to the right, respectively. The results show that the mean of the positions indicated in the condition with both vision and proprioception generally lies off the straight line through the means of the other two conditions. In most cases the mean lies on the side predicted by a model describing the integration of multisensory information. According to this model, the visual information and the proprioceptive information are weighted with direction-dependent weights, the weights being related to the direction-dependent precision of the information in such a way that the available information is used very efficiently. Because the proposed model also can explain the unexpectedly small sizes of the variable errors in the localization of a seen hand that were reported earlier, there is strong evidence to support this model. The results imply that the CNS has knowledge about the direction-dependent precision of the proprioceptive and visual information.},
author = {{Van Beers}, Robert J. and Sittig, Anne C. and {Denier Van Der Gon}, Jan J.},
doi = {10.1152/jn.1999.81.3.1355},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Beers, Sittig, Denier Van Der Gon - 1999 - Integration of proprioceptive and visual position-information An experimentally supported.pdf:pdf},
issn = {00223077},
journal = {Journal of Neurophysiology},
keywords = {A C Sittig,Adult,Female,Humans,J J Gon,MEDLINE,Male,Mental Processes / physiology*,Middle Aged,Models,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Neurological*,Pattern Recognition,Proprioception / physiology*,PubMed Abstract,R J van Beers,Visual / physiology*,doi:10.1152/jn.1999.81.3.1355,pmid:10085361},
number = {3},
pages = {1355--1364},
pmid = {10085361},
publisher = {American Physiological Society},
title = {{Integration of proprioceptive and visual position-information: An experimentally supported model}},
url = {https://pubmed.ncbi.nlm.nih.gov/10085361/},
volume = {81},
year = {1999}
}
@techreport{Bubka,
author = {Bubka, Andrea and Bonato, Frederick and Palmisano, Stephen},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bubka, Bonato, Palmisano - Unknown - Expanding and contracting optical flow patterns and simulator sickness Effects of postural constrai.pdf:pdf},
title = {{Expanding and contracting optical flow patterns and simulator sickness Effects of postural constraints upon saccadic eye movements View project ERP Markers of Auditory Go/NoGo Processing View project}},
url = {https://www.researchgate.net/publication/6347727}
}
@book{Gibson,
abstract = {The principal subject of this book is the visual perception of space. Chapters cover theories of perception, the visual field and visual world, formation of retinal images, a psychophysical theory of perception, stimulus variables for visual depth and distance, size and shape constancy, geometrical space and form, mean, learning, and spatial behavior.},
author = {Gibson, James J},
title = {{The perception of the visual world}},
year = {1950}
}
@inproceedings{Sarupuri2017,
abstract = {We present Trigger Walking, a low-fatigue travel technique for immersive virtual reality which uses hand-held controllers to move about more naturally within a limited physical space. Most commercial applications use some form of teleportation or physical walking for moving around in a virtual space. However, teleportation can be disorienting, due to the sudden change in the environment when teleported to another location. Physical walking techniques are more physically demanding, leading to fatigue. Hence, we explore the use of two spatial controllers that accompany commercial headsets to walk by taking a virtual step each time a controller trigger is pulled. The user has the choice of using the orientation of a single-controller, the average of both controllers, or that of the head to determine the direction of walking, and speed can be controlled by changing the angle of the controller to the Frontal plane.},
author = {Sarupuri, Bhuvaneswari and Chipana, Miriam Luque and Lindeman, Robert W.},
booktitle = {2017 IEEE Symposium on 3D User Interfaces, 3DUI 2017 - Proceedings},
doi = {10.1109/3DUI.2017.7893354},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sarupuri, Chipana, Lindeman - 2017 - Trigger Walking A low-fatigue travel technique for immersive virtual reality.pdf:pdf},
isbn = {9781509067169},
keywords = {HMD,Tracking,entertainment,immersion,training},
month = {apr},
pages = {227--228},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Trigger Walking: A low-fatigue travel technique for immersive virtual reality}},
year = {2017}
}
@inproceedings{Yan2016,
abstract = {The tradeoff between speed and precision is one of the challenging problems of travel interfaces. Sometimes users want to travel long distances (e.g., fly) and care less about precise movement, while other times they want to approach nearby objects in a more-precise way (e.g., walk), and care less about how quickly they move. Between these two extremes there are scenarios when both speed and precision become equally important. In real life, we often seamlessly combine these modes. However, most VR systems support a single travel metaphor, which may only be good for one range of travel, but not others. We present a new VR travel framework which supports three separate multi-touch travel techniques, one for each distance range, but that all use the same device. We use a unifying metaphor of the user's fingers becoming their legs for each of the techniques. We are investigating the usability and user acceptance of the fingers-as-legs metaphor, as well as the efficiency and naturalness of switching between the different travel modes. We conducted an experiment focusing on user performance using the three travel modes, and compared our multi-touch, gesture-based approach with a traditional Gamepad travel interface. The results suggest that participants using a Gamepad interface are more time efficient. However, the quality of completing the tasks with the two input devices was similar, while ForcePad user response was faster for switching between travel modes.},
author = {Yan, Zhixin and Lindeman, Robert W. and Dey, Arindam},
booktitle = {2016 IEEE Symposium on 3D User Interfaces, 3DUI 2016 - Proceedings},
doi = {10.1109/3DUI.2016.7460027},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yan, Lindeman, Dey - 2016 - Let your fingers do the walking A unified approach for efficient short-, medium-, and long-distance travel i.pdf:pdf},
isbn = {9781509008421},
keywords = {3D travel interface,multi-touch gestures},
month = {apr},
pages = {27--30},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Let your fingers do the walking: A unified approach for efficient short-, medium-, and long-distance travel in VR}},
year = {2016}
}
@inproceedings{Griffin2018,
abstract = {To navigate beyond the confines of often limited available positional tracking space, virtual reality (VR) users need to switch from natural walking input to a controller-based locomotion technique, such as teleportation or full locomotion. Overloading the hands with navigation functionality has been considered detrimental to performance given that, in many VR experiences, (i.e., games), controllers are already used for tasks such as shooting or interacting with objects. Existing studies have only evaluated virtual locomotion techniques using a single navigation task. This paper reports on the performance, cognitive load demands, usability, presence and VR sickness occurrence of two hands-busy (full locomotion/teleportation) and two hands-free (tilt/walking-in-place) locomotion methods while participants (n=20) performed a bimanual shooting with navigation task. Though handsfree methods offer a higher presence, they don't outperform handsbusy locomotion methods in terms of performance.},
author = {Griffin, Nathan Navarro and Liu, James and Folmer, Eelke},
booktitle = {CHI PLAY 2018 - Proceedings of the 2018 Annual Symposium on Computer-Human Interaction in Play},
doi = {10.1145/3242671.3242707},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Griffin, Liu, Folmer - 2018 - Evaluation of handsbusy vs handsfree virtual locomotion.pdf:pdf},
isbn = {9781450356244},
keywords = {Bimanual performance,Cognitive load,Full locomotion,Teleportation,Virtual reality; Locomotion},
month = {oct},
pages = {211--219},
publisher = {Association for Computing Machinery, Inc},
title = {{Evaluation of handsbusy vs handsfree virtual locomotion}},
url = {http://dx.doi.org/10.1145/3242671.3242707},
year = {2018}
}
@inproceedings{Forte2019,
abstract = {In recent years there has been a great boom in the use of immersive virtual environments applications, but research into interaction techniques for these technologies has not had the same growth. Therefore, it is necessary to study the user experience of the different forms of interaction that these technologies offer to users and give developers the information needed to use the techniques that best suit their applications and their users. This work is an exploratory study to detect the problems that the users find in this kind of applications. We aim to make an evaluation of a determined set of interaction techniques, both in virtual and augmented reality, attending to the problems produced in the users to know the strengths and weaknesses of each type of interaction technique. With this study, we will be able to make a guide for the developers, in order to give them clues about the best interaction technique for their applications.},
author = {Forte, Juan Luis Berenguel and Vela, Francisco Luis Guti{\'{e}}rrez and Rodr{\'{i}}guez, Patricia Paderewski},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3335595.3336288},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Forte, Vela, Rodr{\'{i}}guez - 2019 - User experience problems in immersive virtual environments.pdf:pdf},
isbn = {9781450371766},
keywords = {Augmented reality,Evaluation,Immersive virtual environments,Interaction techniques,Usability,User experience,Virtual reality},
month = {jun},
publisher = {Association for Computing Machinery},
title = {{User experience problems in immersive virtual environments}},
url = {https://doi.org/10.1145/3335595.3336288},
year = {2019}
}
@techreport{Bhandari,
abstract = {Figure 1: Teleportation discontinuously translates the user's viewpoint over a distance (A → B). The absence of optical flow reduces VR sickness, but also limits the users' ability to perform path integration, i.e., estimating the distance traveled, which can lead to spatial disorientation. Dash merges teleportation with regular locomotion by quickly and continuously moving the user to a destination (A → C), which generates optical flow that allows for path integration. ABSTRACT Teleportation is a popular locomotion technique that lets users navigate beyond the confines of limited available positional tracking space. Because it discontinuously translates the viewpoint, it is considered a safe locomotion method because it doesn't generate any optical flow, and thus reduces the risk of vection induced VR sickness. Though the lack of optical flow minimizes VR sickness, it also limits path integration, e.g., estimating the total distance traveled, and which can lead to spatial disorientation. This paper evaluates a teleportation technique called Dash that quickly but continuously displaces the user's viewpoint and which retains some optical flow cues. A user study with 16 participants compares Dash to regular teleportation and found that it significantly improves path integration while there was no difference in VR sickness.},
author = {Bhandari, Jiwan and Macneilage, Paul and Folmer, Eelke},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhandari, Macneilage, Folmer - 2018 - Teleportation without Spatial Disorientation Using Optical Flow Cues.pdf:pdf},
keywords = {Teleportation,VR Sickness Index Terms: I37 [Computer Graphics]: 3D Graphics and Realism-Virtual Reality,Virtual Locomotion},
title = {{Teleportation without Spatial Disorientation Using Optical Flow Cues}},
year = {2018}
}
@inproceedings{Clifton,
abstract = {We compared two common techniques of controller-based locomotion (teleportation and steering locomotion) in virtual reality (VR) in terms of the cybersickness they produce. Participants had to continuously navigate a commercial VR application for 16 minutes using each technique, while standing and seated. While teleportation produced less cybersickness than steering locomotion on average, a number of participants reported teleportation to be more sickening. These 'telesick' participants were found to have greater medio/lateral positional variability in their spontaneous postural sway than 'steersick' participants prior to VR exposure. We conclude that different individuals may require unique techniques to comfortably locomote in VR.},
author = {Clifton, Jeremy and Palmisano, Stephen},
booktitle = {Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST},
doi = {10.1145/3359996.3364722},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Clifton, Palmisano - 2019 - Comfortable locomotion in VR Teleportation is not a complete solution.pdf:pdf},
isbn = {9781450370011},
keywords = {Cybersickness,Head-Mounted Display,Locomotion,Virtual Reality},
month = {nov},
publisher = {Association for Computing Machinery},
title = {{Comfortable locomotion in VR: Teleportation is not a complete solution}},
year = {2019}
}
@inproceedings{Cardoso2016,
abstract = {In this paper we present a VR locomotion technique based on the Leap Motion device and compare it to other often-used locomotion techniques - gaze-directed locomotion and gamepad-based locomotion. We performed a user experiment to evaluate the three techniques based on their performance (time to complete the task), comfort (through the ISO 9241-9 assessment of comfort questionnaire), and simulation sickness (through the Simulation Sickness Questionnaire). Results indicate that the gamepad technique is both faster and more comfortable than either the Leap Motion-based or the gaze-directed techniques.},
author = {Cardoso, Jorge C.S.},
booktitle = {Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST},
doi = {10.1145/2993369.2996327},
title = {{Comparison of gesture, gamepad, and gaze-based locomotion for VR worlds}},
volume = {02-04-Nove},
year = {2016}
}
@inproceedings{Cardoso2017,
abstract = {In this paper, we present a VR locomotion technique based on the Leap Motion device and compare it to other often-used locomotion techniques - gaze-directed locomotion and gamepad-based locomotion. We performed an exploratory user experiment to evaluate the three techniques based on their performance (time to complete the task), comfort (through the ISO 9241-9 assessment of comfort questionnaire), and simulation sickness (through the Simulation Sickness Questionnaire). Results indicate that the gamepad technique is both faster and more comfortable than either the Leap Motion-based or the gaze-directed techniques. These results suggest that the design of interaction techniques for the Leap Motion device should take into consideration the possible fatigue induced by the prolonged use of the device. For interaction tasks that require high performance, designers should look for alternatives to the Leap Motion device.},
author = {Cardoso, Jorge C.S.},
booktitle = {Proceedings of the International Conference on Interfaces and Human Computer Interaction 2017 - Part of the Multi Conference on Computer Science and Information Systems 2017},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cardoso - 2017 - Gesture-based locomotion in immersive VR worlds with the leap motion controller.pdf:pdf},
title = {{Gesture-based locomotion in immersive VR worlds with the leap motion controller}},
year = {2017}
}
@inproceedings{JacobHabgood2018,
abstract = {The confounding effect of player locomotion on the vestibulo-ocular reflex is one of the principal causes of motion sickness in immersive virtual reality. Continuous motion is particularly problematic for stationary user configurations, and teleportation has become the prevailing approach for providing accessible locomotion. Unfortunately, teleportation can also increase disorientation and reduce a player's sense of presence within a VR environment. This paper presents an alternative locomotion technique designed to preserve accessibility while maintaining feelings of presence. This is a node-based navigation system which allows the player to move between predefined node positions using a rapid, continuous, linear motion. An evaluation was undertaken to compare this locomotion technique with commonly used, teleportation-based and continuous walking approaches. Thirty-six participants took part in a study which examined motion sickness and presence for each technique, while navigating around a virtual house using PlayStation VR. Contrary to intuition, we show that rapid movement speeds reduce players' feelings of motion sickness as compared to continuous movement at normal walking speeds.},
author = {{Jacob Habgood}, M. P. and Moore, David and Wilson, David and Alapont, Sergio},
booktitle = {25th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2018 - Proceedings},
doi = {10.1109/VR.2018.8446130},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jacob Habgood et al. - 2018 - Rapid, Continuous Movement between Nodes as an Accessible Virtual Reality Locomotion Technique.pdf:pdf},
isbn = {9781538633656},
keywords = {Edward Jenner,PlayStation VR,REVEAL.: H.5.1 [Information Interfaces and Present,and virtual realities,augmented,cultural heritage,locomotion,motion-sickness,virtual reality},
month = {aug},
pages = {371--378},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Rapid, Continuous Movement between Nodes as an Accessible Virtual Reality Locomotion Technique}},
year = {2018}
}
@inproceedings{Frommel2017,
abstract = {Entertainment and in particular gaming is currently considered one of the main application scenarios for virtual reality (VR). The majority of current games rely on any form of locomotion through the virtual environment while some techniques can lead to simulator sickness. Game developers are currently implementing a wide variety of locomotion techniques to cope with simulator sickness (e.g. teleportation). In this work we implemented and evaluated four diierent controller-based locomotion methods that are popular in current VR games (free teleport, ,xpoint teleport, touchpad-based, automatic). We conducted a user study (n = 24) in which participants explored a virtual zoo with these four diierent controller-based locomotion methods and assessed their eeects on discomfort, presence, enjoyment, and aaective state. The results of our study show that free teleport locomotion elicited least discomfort and provided the highest scores for enjoyment, presence, and aaective state. With these results we gained valuable insights for developers and researchers implementing grst person locomotion in VR experiences.},
address = {New York, NY, USA},
author = {Frommel, Julian and Sonntag, Sven and Weber, Michael},
booktitle = {Proceedings of the 12th International Conference on the Foundations of Digital Games},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Frommel, Sonntag, Weber - 2017 - EEects of Controller-based Locomotion on Player Experience in a Virtual Reality Exploration Game.pdf:pdf},
isbn = {9781450353199},
keywords = {•Applied computing  Computer games,•Human-centered computing  Virtual reality,•Software and its engineering  Interactive games},
publisher = {ACM},
title = {{EEects of Controller-based Locomotion on Player Experience in a Virtual Reality Exploration Game}},
volume = {6},
year = {2017}
}
@article{Boletsis,
abstract = {The latest technical and interaction advancements within the virtual reality (VR) field have marked a new era, not only for VR, but also for VR locomotion. In this era, well-established, prevalent VR locomotion techniques are mostly used as points of comparison for benchmarking of new VR locomotion designs. At the same time, there is the need for more exploratory, comparative studies of contemporary VR locomotion techniques, so that their distinguished interaction aspects can be documented and guide the design process of new techniques. This article presents a comparative, empirical evaluation study of contemporary and prevalent VR locomotion techniques, examining the user experience (UX) they offer. First, the prevalent VR locomotion techniques are identified based on literature, i.e., walking-in-place, controller/joystick, and teleportation. Twenty-six adults are enrolled in the study and perform a game-like task using the techniques. The study follows a mixed methods approach, utilising the System Usability Scale survey, the Game Experience Questionnaire, and a semistructured interview to assess user experiences. Results indicate that the walking-in-place technique offers the highest immersion but also presents high levels of psychophysical discomfort. Controller/joystick VR locomotion is perceived as easy-to-use due to the users' familiarity with controllers, whereas teleportation is considered to be effective due to its fast navigation, although its visual 'jumps' do break the users' sense of immersion. Based on the interviews, the users focused on the following interaction dimensions to describe their VR locomotion experiences: (i) immersion and flow, (ii) ease-of-use and mastering, (iii) competence and sense of effectiveness, and (iv) psychophysical discomfort. The study implications for VR locomotion are discussed, along with the study limitations and the future direction for research.},
author = {Boletsis, Costas and Cedergren, Jarl Erik},
doi = {10.1155/2019/7420781},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boletsis, Cedergren - 2019 - VR Locomotion in the New Era of Virtual Reality An Empirical Comparison of Prevalent Techniques.pdf:pdf},
issn = {16875907},
journal = {Advances in Human-Computer Interaction},
publisher = {Hindawi Limited},
title = {{VR Locomotion in the New Era of Virtual Reality: An Empirical Comparison of Prevalent Techniques}},
volume = {2019},
year = {2019}
}
@techreport{Bouguila,
abstract = {Omni-directional locomotion systems are yet of little advantage in virtual environments (VEs) with limited large display system, where users may experience visual-less situations when they move in a direction that is not covered by the large screen. This paper presents a new omni-directional locomotion interface based on step-in-place movement and a smart-turntable system to impart users with the ability to move freely in any direction within VEs without loosing sight of the displayed images despite their projection on a limited large screen that do not provide surrounding or 360 o visual feedback. A sensor-embedded turntable is used as a walking platform, on top of which users will stand at its center to perform walk in place and turn in place movements to steer their navigation through the virtual environment. However, as a large turn action may put the screen outside user's visual field of view, the turntable will cancel user's turnings by a smooth and passive rotation in the opposite direction so as to keep user oriented toward the center of the screen. The novelty of the interface is that a) it uses a smart-turntable as walking platform that compensate users' rotations rather than their displacements b) no cable attachments are made to the user body c) user can make many full body rotations without loosing sight of the environment, virtually providing a surrounding display despite the use of limited size screen.},
author = {Bouguila, Laroussi and Ishii, Masahiro and Sato, Makoto},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bouguila, Ishii, Sato - Unknown - Realizing a New Step-in-place Locomotion interface for Virtual Environment with Large Display System.pdf:pdf},
title = {{Realizing a New Step-in-place Locomotion interface for Virtual Environment with Large Display System}}
}
@inproceedings{Ferracani,
abstract = {In this paper we evaluate methods to move 'naturally' in an Immersive Virtual Environment (IVE) visualised through an Head Mounted Display (HMD). Natural interaction is provided through gesture recognition on depth sensors' data. Gestural input solutions in the literature to provide loco-motion are discussed. Two new methods for locomotion are proposed, implemented in a framework used for comparative evaluation. Perceived naturalness and effectiveness of locomotion methods are assessed through qualitative and quantitative measures. Extensive tests are conducted on the locomotion considering also: 1) obstacles in navigation; 2) interaction with virtual objects during locomotion. This is done with the aim to identify methods capable to provide a full body experience in an IVE. Results show that one of the methods for locomotion we propose has a performance comparable to established techniques in literature. Outcomes may be exploited to improve the naturalness of users' movements in IVEs and help to unlock new strategies in providing IVEs for learning, training, collaboration and entertainment, also with respect to users with disabilities.},
address = {New York, NY, USA},
author = {Ferracani, Andrea and Pezzatini, Daniele and Bianchini, Jacopo and Biscini, Gianmarco and Bimbo, Alberto Del},
booktitle = {Proceedings of the 1st International Workshop on Multimedia Alternate Realities},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferracani et al. - Unknown - Locomotion by Natural Gestures for Immersive Virtual Environments.pdf:pdf},
isbn = {9781450345217},
keywords = {Head Mounted Display,Immersive Virtual Reality,Locomotion,Motion Tracking,Natural Interac-tion},
publisher = {ACM},
title = {{Locomotion by Natural Gestures for Immersive Virtual Environments}},
url = {http://dx.doi.org/10.1145/2983298.2983307}
}
@inproceedings{Langbehn,
abstract = {Due to its multimodal nature virtual reality technology imposes new challenges, for example, when it comes to navigating through a virtual environment. Joystick-based controls and teleportation techniques support only limited self-motion experiences, however, other techniques such as redirected walking provide promising solutions to enable near-natural walking, while overcoming limits of the physical space. In this article, we report an experiment that analyzed the effects of the three different locomotion techniques, i. e., (i) joystick-based, (ii) teleportation, and (iii) redirected walking, on the user's cognitive map building of an indoor virtual environment , as well as effectiveness, motion sickness, presence, and user preferences. Our results suggest that redirected walking performs best regarding the user's ability to unconsciously acquire spatial knowledge about the virtual environment. Redirected walking and teleportation were subjectively preferred over joystick by the participants. Furthermore, we found a significant effect of an increased motion sickness for joystick-based navigation. Hence, redirected walking as well as teleportation are locomotion techniques with different benefits and drawbacks, and should be preferred.},
address = {New York, NY, USA},
author = {Langbehn, Eike and Lubos, Paul and Steinicke, Frank},
booktitle = {Proceedings of the Virtual Reality International Conference - Laval Virtual},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Langbehn, Lubos, Steinicke - Unknown - Evaluation of Locomotion Techniques for Room-Scale VR Joystick, Teleportation, and Redirected Wal.pdf:pdf},
isbn = {9781450353816},
keywords = {Virtual reality,cognitive map building,locomotion,navigation,redirected walking,spatial knowledge,teleportation},
number = {18},
publisher = {ACM},
title = {{Evaluation of Locomotion Techniques for Room-Scale VR: Joystick, Teleportation, and Redirected Walking}},
url = {https://doi.org/10.1145/3234253.3234291}
}
@inproceedings{Nabiyouni2015,
abstract = {One of the goals of much virtual reality (VR) research is to increase realism. In particular, many techniques for locomotion in VR attempt to approximate real-world walking. However, it is not yet fully understood how the design of more realistic locomotion techniques affects user task performance. We performed an experiment to compare a semi-natural locomotion technique (based on the Virtusphere device) with a traditional, non-natural technique (based on a game controller) and a fully natural technique (real walking). We found that the Virtusphere technique was significantly slower and less accurate than both of the other techniques. Based on this result and others in the literature, we speculate that locomotion techniques with moderate interaction fidelity will often have performance inferior to both high-fidelity techniques and well-designed low-fidelity techniques. We argue that our experimental results are an effect of interaction fidelity, and perform a detailed analysis of the fidelity of the three locomotion techniques to support this argument.},
author = {Nabiyouni, Mahdi and Saktheeswaran, Ayshwarya and Bowman, Doug A. and Karanth, Ambika},
booktitle = {2015 IEEE Symposium on 3D User Interfaces, 3DUI 2015 - Proceedings},
doi = {10.1109/3DUI.2015.7131717},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nabiyouni et al. - 2015 - Comparing the performance of natural, semi-natural, and non-natural locomotion techniques in virtual reality.pdf:pdf},
isbn = {9781467368865},
keywords = {Effectiveness,Interaction fidelity,Locomotion interaction,Virtusphere},
month = {jun},
pages = {3--10},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Comparing the performance of natural, semi-natural, and non-natural locomotion techniques in virtual reality}},
year = {2015}
}
@inproceedings{Bozgeyikli2016,
abstract = {With the increasing popularity of virtual reality (VR) and new devices getting available with relatively lower costs, more and more video games have been developed recently. Most of these games use first person interaction techniques since it is more natural for Head Mounted Displays (HMDs). One of the most widely used interaction technique in VR video games is locomotion that is used to move user's viewpoint in virtual environments. Locomotion is an important component of video games since it can have a strong influence on user experience. In this study, a new locomotion technique we called "Point \& Teleport" is described and compared with two commonly used VR locomotion techniques of walk-in-place and joystick. In this technique, users simply point where they want to be in virtual world and they are teleported to that position. As a major advantage, it is not expected to introduce motion sickness since it does not involve any visible translational motion. In this study, two VR experiments were designed and performed to analyze the Point \& Teleport technique. In the first experiment, Point \& Teleport was compared with walkin-place and joystick locomotion techniques. In the second experiment, a direction component was added to the Point \& Teleport technique so that the users could specify their desired orientation as well. 16 users took part in both experiments. Results indicated that Point \& Teleport is a fun and user friendly locomotion method whereas the additional direction component degraded the user experience.},
author = {Bozgeyikli, Evren and Raij, Andrew and Katkoori, Srinivas and Dubey, Rajiv},
booktitle = {CHI PLAY 2016 - Proceedings of the 2016 Annual Symposium on Computer-Human Interaction in Play},
doi = {10.1145/2967934.2968105},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bozgeyikli et al. - 2016 - Point \& Teleport locomotion technique for virtual reality.pdf:pdf},
isbn = {9781450344562},
keywords = {Locomotion,Teleportation,Virtual reality},
month = {oct},
pages = {205--216},
publisher = {Association for Computing Machinery, Inc},
title = {{Point \& Teleport locomotion technique for virtual reality}},
url = {http://dx.doi.org/10.1145/2967934.2968105},
year = {2016}
}
@misc{Boletsis2017,
abstract = {The latest technical and interaction advancements that took place in the Virtual Reality (VR) field have marked a new era, not only for VR, but also for VR locomotion. Although the latest advancements in VR locomotion have raised the interest of both researchers and users in analyzing and experiencing current VR locomotion techniques, the field of research on VR locomotion, in its new era, is still uncharted. In this work, VR locomotion is explored through a systematic literature review investigating empirical studies of VR locomotion techniques from 2014–2017. The review analyzes the VR locomotion techniques that have been studied, their interaction-related characteristics and the research topics that were addressed in these studies. Thirty-six articles were identified as relevant to the literature review, and the analysis of the articles resulted in 73 instances of 11 VR locomotion techniques, such as real-walking, walking-in-place, point and teleport, joystick-based locomotion, and more. Results showed that since the VR revival, the focus of VR locomotion research has been on VR technology and various technological aspects, overshadowing the investigation of user experience. From an interaction perspective, the majority of the utilized and studied VR locomotion techniques were found to be based on physical interaction, exploiting physical motion cues for navigation in VR environments. A significant contribution of the literature review lies in the proposed typology for VR locomotion, introducing four distinct VR locomotion types: motion-based, room scale-based, controller-based and teleportation-based locomotion.},
author = {Boletsis, Costas},
booktitle = {Multimodal Technologies and Interaction},
doi = {10.3390/mti1040024},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boletsis - 2017 - The new era of virtual reality locomotion A systematic literature review of techniques and a proposed typology.pdf:pdf},
issn = {24144088},
keywords = {Human-computer interaction,Literature review,Locomotion,Typology,Virtual reality},
month = {dec},
number = {4},
pages = {24},
publisher = {MDPI AG},
title = {{The new era of virtual reality locomotion: A systematic literature review of techniques and a proposed typology}},
url = {www.mdpi.com/journal/mti},
volume = {1},
year = {2017}
}
@article{Smith,
abstract = {Fig. 1. A subject brings her hands together, bends her middle fingers, pivots her hands around this region of contact, intertwines her remaining fingers, and wiggles her middle fingers. Top row: Input images. Bottom row: Our tracking results. Our approach is able to track through the significant amount of self-contact and and self-occlusion induced by this two-handed performance. Many of the actions that we take with our hands involve self-contact and occlusion: shaking hands, making a fist, or interlacing our fingers while thinking. This use of of our hands illustrates the importance of tracking hands through self-contact and occlusion for many applications in computer vision and graphics, but existing methods for tracking hands and faces are not designed to treat the extreme amounts of self-contact and self-occlusion exhibited by common hand gestures. By extending recent advances in vision-based tracking and physically based animation, we present the first algorithm capable of tracking high-fidelity hand deformations through highly self-contacting and self-occluding hand gestures, for both single hands and two hands. By constraining a vision-based tracking algorithm with a physically based deformable model, we obtain an algorithm that is robust to the ubiquitous self-interactions and massive self-occlusions exhibited by common hand gestures, allowing us to track two hand interactions and some of the most difficult possible configurations of a human hand.},
author = {Smith, Breannan and Hodgins, Jessica K and Smith, • Breannan and Wu, Chenglei and Wen, He and Peluse, Patrick and Sheikh, Yaser and Shiratori, Takaaki},
doi = {10.1145/3414685.3417768},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Smith et al. - Unknown - Constraining Dense Hand Surface Tracking with Elasticity.pdf:pdf},
journal = {ACM Trans. Graph},
number = {6},
title = {{Constraining Dense Hand Surface Tracking with Elasticity}},
url = {https://doi.org/10.1145/3414685.3417768},
volume = {39}
}
@techreport{Moon,
abstract = {Analysis of hand-hand interactions is a crucial step towards better understanding human behavior. However, most researches in 3D hand pose estimation have focused on the isolated single hand case. Therefore, we firstly propose (1) a large-scale dataset, InterHand2.6M, and (2) a baseline network, InterNet, for 3D interacting hand pose estimation from a single RGB image. The proposed InterHand2.6M consists of 2.6M labeled single and interacting hand frames under various poses from multiple subjects. Our InterNet simultaneously performs 3D single and interacting hand pose estimation. In our experiments, we demonstrate big gains in 3D interacting hand pose estimation accuracy when leveraging the interacting hand data in InterHand2.6M. We also report the accuracy of InterNet on InterHand2.6M, which serves as a strong baseline for this new dataset. Finally, we show 3D interacting hand pose estimation results from general images. Our code and dataset are available 1 .},
author = {Moon, Gyeongsik and Yu, Shoou-I and Wen, He and Shiratori, Takaaki and Lee, Kyoung Mu},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Moon et al. - Unknown - InterHand2.6M A Dataset and Baseline for 3D Interacting Hand Pose Estimation from a Single RGB Image.pdf:pdf},
title = {{InterHand2.6M: A Dataset and Baseline for 3D Interacting Hand Pose Estimation from a Single RGB Image}},
url = {https://mks0601.github.io/InterHand2.6M/}
}
@article{Luca,
abstract = {Figure 1: Features of the Locomotion Vault interactive database and visualization include: filtering by attributes (left image), an animated gallery with individual technique descriptions for over 100 locomotion techniques (middle), and two similarity graphs that are expert-created or calculated from the attributes (right). ABSTRACT Numerous techniques have been proposed for locomotion in virtual reality (VR). Several taxonomies consider a large number of attributes (e.g., hardware, accessibility) to characterize these techniques. However, finding the appropriate locomotion technique (LT) and identifying gaps for future designs in the high-dimensional space of attributes can be quite challenging. To aid analysis and innovation, we devised Locomotion Vault (https://locomotionvault. github.io/), a database and visualization of over 100 LTs from academia and industry. We propose similarity between LTs as a metric to aid navigation and visualization. We show that similarity based on attribute values correlates with expert similarity assessments (a method that does not scale). Our analysis also highlights an inherent trade-off between simulation sickness and accessibility across LTs. As such, Locomotion Vault shows to be a tool that unifies information on LTs and enables their standardization and large-scale comparison to help understand the space of possibilities in VR locomotion. CCS CONCEPTS • Human-centered computing → User interface management systems; Information visualization.},
author = {Luca, Massimiliano Di and Seifi, Hasti and Egan, Simon and Gonzalez-Franco, Mar},
doi = {10.1145/3411764.3445319},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Luca et al. - Unknown - Locomotion Vault the Extra Mile in Analyzing VR Locomotion Tech-niques(2).pdf:pdf},
isbn = {978-1-4503-8096-6},
keywords = {VR,database,locomotion method,locomotion technique,movement,navigation,travel-ing,visualization},
title = {{Locomotion Vault: the Extra Mile in Analyzing VR Locomotion Tech-niques}},
url = {https://doi.org/10.1145/3411764.3445319}
}
@article{Huang,
abstract = {Background Within a virtual environment (VE) the control of locomotion (e.g., self-travel) is critical for creating a realistic and functional experience. Usually the direction of locomotion, while using a head-mounted display (HMD), is determined by the direction the head is pointing and the forward or backward motion is controlled with a hand held controllers. However, hand held devices can be difficult to use while the eyes are covered with a HMD. Free hand gestures, that are tracked with a camera or a hand data glove, have an advantage of eliminating the need to look at the hand controller but the design of hand or finger gestures for this purpose has not been well developed. Methods This study used a depth-sensing camera to track fingertip location (curling and straightening the fingers), which was converted to forward or backward self-travel in the VE. Fingertip position was converted to self-travel velocity using a mapping function with three parameters: a region of zero velocity (dead zone) around the relaxed hand position, a linear relationship of fingertip position to velocity (slope or/J) beginning at the edge of the dead zone, and an exponential relationship rather than a linear one mapping fingertip position to velocity (exponent). Using a HMD, participants moved forward along a virtual road and stopped at a target on the road by controlling self-travel velocity with finger flexion and extension. Each of the 3 mapping function parameters was tested at 3 levels. Outcomes measured included usability ratings, fatigue, nausea, and time to complete the tasks. Results Twenty subjects participated but five did not complete the study due to nausea. The size of the dead zone had little effect on performance or usability. Subjects preferred lower $\beta$ values which were associated with better subjective ratings of control and reduced time to complete the task, especially for large targets. Exponent values of 1.0 or greater were preferred and reduced the time to complete the task, especially for small targets. Conclusions Small finger movements can be used to control velocity of self-travel in VE. The functions used for converting fingertip position to movement velocity influence usability and performance.},
author = {HUANG, Rachel and HARRIS-ADAMSON, Carisa and ODELL, Dan and REMPEL, David},
doi = {10.3724/sp.j.2096-5796.2018.0007},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/HUANG et al. - 2019 - Design of finger gestures for locomotion in virtual reality.pdf:pdf},
issn = {20965796},
journal = {Virtual Reality \& Intelligent Hardware},
month = {feb},
number = {1},
pages = {1--9},
publisher = {Elsevier BV},
title = {{Design of finger gestures for locomotion in virtual reality}},
volume = {1},
year = {2019}
}
@inproceedings{Davis,
abstract = {The uptake of new interface technologies, such as the Oculus Rift have generated renewed interest in virtual reality especially for private entertainment use. However, long standing issues with unwanted side effects, such as nausea from cybersickness, continue to impact on the general use of devices such as head mounted displays. This in turn has slowed the uptake of more immersive interfaces for computer gaming and indeed more serious applications in training and health. In this paper we report a systematic review in the area of cybersickness with a focus on measuring the diverse symptoms experienced. Indeed the related conditions of simulator sickness and motion sickness have previously been well studied and yet many of the issues are unresolved. Here we report on these issues along with a number of measures, both subjective and objective in nature, using either questionnaires or psychophysiological measures that have been used to study cybersickness. We also report on the factors, individual, device related and task dependent that impact on the condition. We conclude that there remains a need to develop more cost-effective and objective physiological measures of both the impact of cybersickness and a person's susceptibility to the condition.},
address = {New York, NY, USA},
author = {Davis, Simon and Nesbitt, Keith and Nalivaiko, Eugene},
booktitle = {Proceedings of the 2014 Conference on Interactive Entertainment},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Davis, Nesbitt, Nalivaiko - 2014 - A Systematic Review of Cybersickness.pdf:pdf},
isbn = {9781450327909},
keywords = {Artificial,Ergonomics General Terms Design,H51 Multimedia Information Systems,Human Factors Keywords Cybersickness,Oculus Rift,and virtual realities H52 User Interfaces,augmented,motion sickness,simulator sickness},
publisher = {ACM},
title = {{A Systematic Review of Cybersickness}},
url = {http://dx.doi.org/10.1145/2677758.2677780},
year = {2014}
}
@phdthesis{Stone,
abstract = {Stone Iii, William B., "Psychometric evaluation of the Simulator Sickness Questionnaire as a measure of cybersickness" (2017). Graduate Theses and Dissertations. 15429.},
address = {Ames},
author = {{Stone Iii}, William B.},
booktitle = {Graduate Theses and Dissertations},
doi = {10.31274/etd-180810-5050},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Stone Iii - 2017 - Psychometric evaluation of the Simulator Sickness Questionnaire as a measure of cybersickness.pdf:pdf},
keywords = {Cybersickness,Psychometrics,Simulator sickness,Video games,Virtual reality,Visually-induced motion sickness},
month = {jan},
school = {Iowa State University, Digital Repository},
title = {{Psychometric evaluation of the Simulator Sickness Questionnaire as a measure of cybersickness}},
url = {https://lib.dr.iastate.edu/etd/15429/},
year = {2017}
}
@inproceedings{Stanney,
abstract = {Factor analysis of a large number of motion sickness self-reports from exposure to military flight simulators revealed three separate clusters of symptoms. Based on this analysis a symptom profile emerged for simulators where Oculomotor symptoms predominated, followed by Nausea and least by Disorientation-like symptoms. Current users of virtual environment (VE) systems have also begun to report varying degrees of what they are calling cybersickness, which initially appeared to be similar to simulator sickness. We have found, after examination of eight experiments using different VE systems, that the profile of cybersickness is sufficiently different from simulator sickness - with Disorientation being the predominant symptom and Oculomotor the least. The total severity of cybersickness was also found to be approximately three times greater than that of simulator sickness. Perhaps these different strains of motion sickness may provide insight into the different causes of the two maladies.},
author = {Stanney, Kay M. and Kennedy, Robert S. and Drexler, Julie M.},
booktitle = {Proceedings of the Human Factors and Ergonomics Society},
doi = {10.1177/107118139704100292},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Stanney, Kennedy, Drexler - 1997 - Cybersickness is not simulator sickness.pdf:pdf},
issn = {10711813},
month = {nov},
pages = {1138--1141},
publisher = {Human Factors and Ergonomics Society, Inc.},
title = {{Cybersickness is not simulator sickness}},
url = {https://journals.sagepub.com/doi/10.1177/107118139704100292},
volume = {2},
year = {1997}
}
@article{LaViola,
abstract = {An important and troublesome problem with current virtual environment (VE) technology is the tendency for some users to exhibit symptoms that parallel symptoms of classical motion sickness both during and after the VE experience. This type of sickness, cybersickness, is distinct from motion sickness in that the user is often stationary but has a compelling sense of self motion through moving visual imagery. Unfortunately, there are many factors that can cause cybersickness and there is no foolproof method for eliminating the problem. In this paper, I discuss a number of the primary factors that contribute to the cause of cybersickness, describe three conflicting cybersickness theories that have been postulated, and discuss some possible methods for reducing cybersickness in VEs.},
author = {LaViola, Joseph J.},
doi = {10.1145/333329.333344},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/LaViola - 2000 - A discussion of cybersickness in virtual environments.pdf:pdf},
issn = {0736-6906},
journal = {ACM SIGCHI Bulletin},
month = {jan},
number = {1},
pages = {47--56},
publisher = {Association for Computing Machinery (ACM)},
title = {{A discussion of cybersickness in virtual environments}},
url = {https://dl.acm.org/doi/abs/10.1145/333329.333344},
volume = {32},
year = {2000}
}
@incollection{Golding,
abstract = {Over 2000 years ago the Greek physician Hippocrates wrote, “sailing on the sea proves that motion disorders the body.” Indeed, the word “nausea” derives from the Greek root word naus, hence “nautical,” meaning a ship. The primary signs and symptoms of motion sickness are nausea and vomiting. Motion sickness can be provoked by a wide variety of transport environments, including land, sea, air, and space. The recent introduction of new visual technologies may expose more of the population to visually induced motion sickness. This chapter describes the signs and symptoms of motion sickness and different types of provocative stimuli. The “how” of motion sickness (i.e., the mechanism) is generally accepted to involve sensory conflict, for which the evidence is reviewed. New observations concern the identification of putative “sensory conflict” neurons and the underlying brain mechanisms. But what reason or purpose does motion sickness serve, if any? This is the “why” of motion sickness, which is analyzed from both evolutionary and nonfunctional maladaptive theoretic perspectives. Individual differences in susceptibility are great in the normal population and predictors are reviewed. Motion sickness susceptibility also varies dramatically between special groups of patients, including those with different types of vestibular disease and in migraineurs. Finally, the efficacy and relative advantages and disadvantages of various behavioral and pharmacologic countermeasures are evaluated.},
author = {Golding, J. F.},
booktitle = {Handbook of Clinical Neurology},
doi = {10.1016/B978-0-444-63437-5.00027-3},
issn = {22124152},
keywords = {motion sickness,nausea,transport,vestibular,visual displays,vomiting},
pages = {371--390},
pmid = {27638085},
publisher = {Elsevier B.V.},
title = {{Motion sickness}},
volume = {137},
year = {2016}
}
@techreport{Johnson,
author = {Johnson, David M and Simutis, Zita M},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Johnson, Simutis - 2005 - Introduction to and Review of Simulator Sickness Research.pdf:pdf},
title = {{Introduction to and Review of Simulator Sickness Research}},
year = {2005}
}
@book{Reason,
author = {Reason, J.T. and Brand, J.J.},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Reason, Brand - 1975 - Motion Sickness.bibtex:bibtex},
isbn = {9780125840507},
publisher = {Academic Press},
title = {{Motion Sickness}},
url = {https://books.google.de/books?id=JMxrAAAAMAAJ},
year = {1975}
}
@inproceedings{Pohl2021,
abstract = {Figure 1: Poros enables users to bring portions of distant spaces closer so that they can interact with and across them. Shown here are two proxies, linked to marked spaces (shown in the same color) around two different bookshelves. The user is about to move a book from one space to the other. In addition to direct interactions through them, users can move and arrange proxies, as well as perform operations on them, such as merging and aligning. ABSTRACT A compelling property of virtual reality is that it allows users to interact with objects as they would in the real world. However, such interactions are limited to space within reach. We present Poros, a system that allows users to rearrange space. After marking a portion of space, the distant marked space is mirrored in a nearby proxy. Thereby, users can arrange what is within their reachable space, making it easy to interact with multiple distant spaces as well as nearby objects. Proxies themselves become part of the scene and can be moved, rotated, scaled, or anchored to other objects. Furthermore, they can be used in a set of higher-level interactions such as alignment and action duplication. We show how Poros enables a variety of tasks and applications and also validate its effectiveness through an expert evaluation.},
address = {New York, NY, USA},
author = {Pohl, Henning and Lilija, Klemen and McIntosh, Jess and Hornb{\ae}k, Kasper},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3411764.3445685},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pohl et al. - 2021 - Poros Configurable Proxies for Distant Interactions in VR.pdf:pdf},
isbn = {9781450380966},
keywords = {3D user interface,portals,virtual reality,worlds in miniature},
month = {may},
pages = {1--12},
publisher = {ACM},
title = {{Poros: Configurable Proxies for Distant Interactions in VR}},
url = {https://dl.acm.org/doi/10.1145/3411764.3445685},
year = {2021}
}
@inproceedings{Liu2018,
abstract = {Teleportation is a popular locomotion technique that lets users safely navigate beyond the confines of available positional tracking space without inducing VR sickness. Because available walking space is limited and teleportation is faster than walking, a risk with using teleportation is that users might end up abandoning walking input and only relying on teleportation, which is considered detrimental to presence. We present redirected teleportation; an improved version of teleportation that uses iterative non-obtrusive reorientation and repositioning using a portal to redirect the user back to the center of the tracking space, where available walking space is larger. A user study compares the effectiveness, accuracy, and usability of redirected teleportation with regular teleportation using a navigation task in three different environments. Results show that redirected teleportation allows for a better utilization of available tracking space than regular teleportation, as it requires significantly fewer teleportations, while users walk more and use a larger portion of the available tracking space.},
address = {New York, NY, USA},
author = {Liu, James and Parekh, Hirav and Al-Zayer, Majed and Folmer, Eelke},
booktitle = {UIST 2018 - Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology},
doi = {10.1145/3242587.3242601},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2018 - Increasing walking in VR using redirected teleportation.pdf:pdf},
isbn = {9781450359481},
keywords = {Locomotion,Positional tracking,Teleportation,Virtual reality},
month = {oct},
pages = {521--529},
publisher = {Association for Computing Machinery, Inc},
title = {{Increasing walking in VR using redirected teleportation}},
url = {https://dl.acm.org/doi/10.1145/3242587.3242601},
year = {2018}
}
@techreport{Kiyokawa,
abstract = {This paper proposes a tunnel window, a versatile three dimensional interaction technique, for both navigation and remote object manipulation in a large scale virtual environment. A tunnel window, which is created at an arbitrary position in space using a set of hand gesture commands, provides a secondary view whose viewpoint can be controlled independently from that of the primary view. A tunnel window allows various kinds of seamless teleportation operations including teleportation of the user's viewpoint and that of a virtual object from one position to another by simply passing through the window frame. To extend the interaction scheme, a variety of transformation combinations of the relevant coordinate systems, i.e. those of a user, a window frame, and primary and secondary scenes, have been considered. This paper describes basic concepts and design of a tunnel window interface, its implementation, and variations of the tunnel window scheme.},
author = {Kiyokawa, Kiyoshi and Takemura, Haruo},
title = {{A Tunnel Window and Its Variations: Seamless Teleportation Techniques in a Virtual Environment}}
}
@misc{TeleportSystemOverview,
title = {{TeleportSystemOverview | Microsoft Docs}},
url = {https://docs.microsoft.com/en-us/windows/mixed-reality/mrtk-unity/features/teleport-system/teleport-system},
urldate = {2021-05-03}
}
@techreport{Argelaguet,
abstract = {Virtual environments can be infinitely large, but users only have a limited amount of space in the physical world. One way to navigate within large virtual environments is through teleportation. Teleportation requires two steps: targeting a place and sudden shifting. Conventional teleportation uses a controller to point to a target position and a button press or release to immediately teleport the user to the position. Since the teleportation does not require physical movement, the user can explore the entire virtual environment. However, as this is supernatural and can lead to momentary disorientation, it can break the sense of presence, and thus degrade the overall virtual reality experience. To compensate for the downside of this technique, we explore the effects of a jumping gesture as a teleportation trigger. We conducted a study with two factors: 1) triggering method (Jumping and Standing), and 2) targeting method (Head-direction and Controller). We found that the conventional way of using a controller while standing showed better efficiency, the highest usability and lower cybersickness. Nevertheless, Jump-ing+Controller invoked a high sense of engagement and fun, and therefore provides an interesting new technique, especially for VR games.},
author = {Argelaguet, F and Mcmahan, R P and Sugimoto, M},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Argelaguet, Mcmahan, Sugimoto - Unknown - On the Use of Jumping Gestures for Immersive Teleportation in VR.pdf:pdf},
keywords = {Mixed / augmented reality,Teleportation, Virtual Reality, Locomotion Techniq,Virtual reality},
title = {{On the Use of Jumping Gestures for Immersive Teleportation in VR}}
}
@article{Schafer2021,
abstract = {Virtual Reality (VR) technology offers users the possibility to immerse and freely navigate through virtual worlds. An important component for achieving a high degree of immersion in VR is locomotion. Often discussed in the literature, a natural and effective way of controlling locomotion is still a general problem which needs to be solved. Recently, VR headset manufacturers have been integrating more sensors, allowing hand or eye tracking without any additional required equipment. This enables a wide range of application scenarios with natural freehand interaction techniques where no additional hardware is required. This paper focuses on techniques to control teleportation-based locomotion with hand gestures, where users are able to move around in VR using their hands only. With the help of a comprehensive study involving 21 participants, four different techniques are evaluated. The effectiveness and efficiency as well as user preferences of the presented techniques are determined. Two two-handed and two one-handed techniques are evaluated, revealing that it is possible to move comfortable and effectively through virtual worlds with a single hand only.},
author = {Sch{\"{a}}fer, Alexander and Reis, Gerd and Stricker, Didier},
doi = {10.3390/electronics10060715},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sch{\"{a}}fer, Reis, Stricker - 2021 - Controlling Teleportation-Based Locomotion in Virtual Reality with Hand Gestures A Comparative Evaluat.pdf:pdf},
keywords = {VR,bare hand,freehand,gestural input,gestures,hands-free,locomotion,movement,navigation,virtual reality},
title = {{Controlling Teleportation-Based Locomotion in Virtual Reality
with Hand Gestures: A Comparative Evaluation of
Two-Handed and One-Handed Techniques}},
url = {https://doi.org/10.3390/electronics10060715},
year = {2021}
}
@misc{Interhaptics,
title = {{Hand Tracking for Virtual Reality (VR) \& Mixed Reality (MR) | Interhaptics - Haptics and Interactions for Virtual Reality (VR) and Mixed Reality (MR)}},
url = {https://www.interhaptics.com/products/hand-tracking-for-vr-and-mr},
urldate = {2021-04-24}
}
@article{Ardito2014,
abstract = {Recent advances in computing devices push researchers to envision new interaction modalities that go beyond traditional mouse and keyboard input. Typical examples are large displays for which researchers hope to create more "natural" means of interaction by using human gestures and body movements as input. In this article, we reflect about this goal of designing gestures that people can easily understand and use and how designers of gestural interaction can capitalize on the experience of 30 years of research on visual languages to achieve it. Concretely, we argue that gestures can be regarded as "visual expressions to convey meaning" and thus are a visual language. Based on what we have learned from visual language research in the past, we then explain why the design of a generic gesture set or language that spans many applications and devices is likely to fail. We also discuss why we recommend using gestural manipulations that enable users to directly manipulate on-screen objects instead of issuing commands with symbolic gestures whose meaning varies among different users, contexts, and cultures.},
author = {Ardito, Carmelo and Costabile, Maria Francesca and Jetter, Hans Christian},
doi = {10.1016/j.jvlc.2014.07.002},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ardito, Costabile, Jetter - 2014 - Gestures that people can understand and use.pdf:pdf},
issn = {1045926X},
journal = {Journal of Visual Languages and Computing},
keywords = {Gestural languages,Manipulations,Symbolic gestures,Visual expressions},
month = {oct},
number = {5},
pages = {572--576},
publisher = {Academic Press},
title = {{Gestures that people can understand and use}},
volume = {25},
year = {2014}
}
@inproceedings{Stern2006,
abstract = {A global approach to hand gesture vocabulary design is proposed which includes human as well as technical design factors. The method of selecting gestures for preconceived command vocabularies has not been addressed in a systematic manner. Present methods are ad hoc. In an analytical approach technological factors of gesture recognition accuracy are easily obtained and well studied. Conversely, it is difficult to obtain measures of human centered desires (intuitiveness, comfort), These factors, being subjective, are costly and time consuming to obtain, and hence we have developed automated methods for acquisition of these data through specially designed applications. Results of the intuitiveness experiments showed when commands are presented as stimuli the gestural responses vary widely over a population of subjects. This result refutes the hypothesis that there exist universal common gestures to express user intentions or commands. {\textcopyright} 2006 IEEE.},
author = {Stern, Helman I. and Wachs, Juan P. and Edan, Yael},
booktitle = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
doi = {10.1109/ICSMC.2006.384767},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Stern, Wachs, Edan - 2006 - Human factors for design of hand gesture human - Machine interaction.pdf:pdf},
isbn = {1424401003},
issn = {1062922X},
keywords = {Hand gesture,Human factors,Intuitive interfaces,Man-machine interaction,Optimal vocabulary},
month = {oct},
pages = {4052--4056},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Human factors for design of hand gesture human - Machine interaction}},
url = {http://ieeexplore.ieee.org/document/4274532/},
volume = {5},
year = {2006}
}
@article{Lu2020,
abstract = {Hand gestures provide a natural and easy-to-use way to input commands. However, few works have studied the design space of bimanual hand gestures or attempted to infer gestures that involve devices on both hands. We explore the design space of hand-to-hand gestures, a group of gestures that are performed by touching one hand with the other hand. Hand-to-hand gestures are easy to perform and provide haptic feedback on both hands. Moreover, hand-to-hand gestures generate simultaneous vibration on two hands that can be sensed by dual off-the-shelf wrist-worn devices. In this work, we derive a hand-to-hand gesture vocabulary with subjective ratings from users and select gesture sets for real-life scenarios. We also take advantage of devices on both wrists to demonstrate their gesture-sensing capability. Our results show that the recognition accuracy for fourteen gestures is 94.6% when the user is stationary, and the accuracy for five gestures is 98.4% or 96.3% when the user is walking or running, respectively. This is significantly more accurate than a single device worn on either wrist. Our further evaluation also validates that users can easily remember hand-to-hand gestures and use our technique to invoke commands in real-life contexts.},
author = {Lu, Yiqin and Huang, Bingjian and Yu, Chun and Liu, Guahong and Shi, Yuanchun},
doi = {10.1145/3380984},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu et al. - 2020 - Designing and Evaluating Hand-to-Hand Gestures with Dual Commodity Wrist-Worn Devices.pdf:pdf},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol},
keywords = {hand gesture,locomotion,motion correlation,wearable device},
pages = {27},
title = {{Designing and Evaluating Hand-to-Hand Gestures with Dual Commodity Wrist-Worn Devices}},
url = {https://doi.org/10.1145/3380984},
volume = {4},
year = {2020}
}
@inproceedings{Vatavu2012,
abstract = {As researchers and industry alike are proposing TV interfaces that use gestures in their designs, understanding users' preferences for gesture commands becomes an important problem. However, no rules or guidelines currently exist to assist designers and practitioners of such interfaces. The paper presents the results of the first study investigating users' preferences for free-hand gestures when controlling the TV set. By conducting an agreement analysis on user-elicited gestures, a set of gesture commands is proposed for basic TV control tasks. Also, guidelines and recommendations issued from observed user behavior are provided to assist practitioners interested in prototyping free-hand gestural designs for the interactive TV. {\textcopyright} 2012 ACM.},
address = {New York, New York, USA},
author = {Vatavu, Radu Daniel},
booktitle = {EuroiTV'12 - Proceedings of the 10th European Conference on Interactive TV and Video},
doi = {10.1145/2325616.2325626},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Vatavu - 2012 - User-defined gestures for free-hand TV control.pdf:pdf},
isbn = {9781450311076},
keywords = {Kinect,TV,experiment,free-hand,gesture recognition,gestures,guessability,interactive TV,living room,study,user-defined},
pages = {45--48},
publisher = {ACM Press},
title = {{User-defined gestures for free-hand TV control}},
url = {http://dl.acm.org/citation.cfm?doid=2325616.2325626},
year = {2012}
}
@incollection{Lin2017,
abstract = {Virtual reality requires high levels of interaction with the user, a type of human computer interaction. Interactions that match the way humans usually interact with their surroundings should improve training effectiveness. A 3D hand gesture based interface allows users to control the position and orientation of 3D objects by simply moving their hands, thereby, creating a more naturalistic interaction process. The design of hand gestures should be evaluated to determine design features that are the most effective and comfortable for the user. The purpose of this study was to evaluate parameters for the design of 3D hand gestures for object manipulation in virtual reality to optimize productivity and usability. Twenty participants completed object manipulation tasks while wearing an Oculus Rift headset with a mounted Leap Motion depth sensor camera to capture hand gestures. Independent variables were distance from hand to object, hand posture threshold for grab and release, and grab locations on object. The dependent variables were time for task completion and subjective measures of control, fatigue, motion sickness, and preference. The preferred gesture design parameter was related to better control and reduced time to complete the tasks. In conclusion, this study identified important gesture design features that can be optimized to improve usability and throughput for an object manipulation task in Virtual Reality.},
author = {Lin, Wanhong and Du, Lear and Harris-Adamson, Carisa and Barr, Alan and Rempel, David},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-58071-5_44},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin et al. - 2017 - Design of hand gestures for manipulating objects in virtual reality.pdf:pdf},
issn = {16113349},
keywords = {3D hand gestures,Hand postures,Human-computer interaction},
pages = {584--592},
publisher = {Springer Verlag},
title = {{Design of hand gestures for manipulating objects in virtual reality}},
url = {https://link.springer.com/chapter/10.1007/978-3-319-58071-5_44},
volume = {10271},
year = {2017}
}
@article{Pereira2015,
abstract = {Objective: The purpose of this study was to develop a lexicon for 3-D hand gestures for common humancomputer interaction (HCI) tasks by considering usability and effort ratings. Background: Recent technologies create an opportunity for developing a free-form 3-D hand gesture lexicon for HCI. Method: Subjects (N = 30) with prior experience using 2-D gestures on touch screens performed 3-D gestures of their choice for 34 common HCI tasks and rated their gestures on preference, match, ease, and effort. Videos of the 1,300 generated gestures were analyzed for gesture popularity, order, and response times. Gesture hand postures were rated by the authors on biomechanical risk and fatigue. Results: A final task gesture set is proposed based primarily on subjective ratings and hand posture risk. The different dimensions used for evaluating task gestures were not highly correlated and, therefore, measured different properties of the taskgesture match. Application: A method is proposed for generating a user-developed 3-D gesture lexicon for common HCIs that involves subjective ratings and a posture risk rating for minimizing arm and hand fatigue.},
author = {Pereira, Anna and Wachs, Juan P. and Park, Kunwoo and Rempel, David},
doi = {10.1177/0018720814559307},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pereira et al. - 2015 - A user-developed 3-D hand gesture set for human-computer interaction.pdf:pdf},
issn = {15478181},
journal = {Human Factors},
keywords = {HCI,fatigue,gesture,human-computer interaction,usability},
month = {jun},
number = {4},
pages = {607--621},
pmid = {25977321},
publisher = {SAGE Publications Inc.},
title = {{A user-developed 3-D hand gesture set for human-computer interaction}},
url = {http://journals.sagepub.com/doi/10.1177/0018720814559307},
volume = {57},
year = {2015}
}
@article{Rempel2014,
abstract = {The design and selection of 3D modeled hand gestures for human-computer interaction should follow principles of natural language combined with the need to optimize gesture contrast and recognition. The selection should also consider the discomfort and fatigue associated with distinct hand postures and motions, especially for common commands. Sign language interpreters have extensive and unique experience forming hand gestures and many suffer from hand pain while gesturing. Professional sign language interpreters (N=24) rated discomfort for hand gestures associated with 47 characters and words and 33 hand postures. Clear associations of discomfort with hand postures were identified. In a nominal logistic regression model, high discomfort was associated with gestures requiring a flexed wrist, discordant adjacent fingers, or extended fingers. These and other findings should be considered in the design of hand gestures to optimize the relationship between human cognitive and physical processes and computer gesture recognition systems for human-computer input. {\textcopyright} 2014 Elsevier Ltd.},
author = {Rempel, David and Camilleri, Matt J. and Lee, David L.},
doi = {10.1016/j.ijhcs.2014.05.003},
file = {:C\:/Users/phili/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rempel, Camilleri, Lee - 2014 - The design of hand gestures for human-computer interaction Lessons from sign language interpreters.pdf:pdf},
issn = {10959300},
journal = {International Journal of Human Computer Studies},
keywords = {Computer input,Computer interface,Gesture-based interaction,Hand postures,Multi-touch},
month = {oct},
number = {10-11},
pages = {728--735},
publisher = {Academic Press},
title = {{The design of hand gestures for human-computer interaction: Lessons from sign language interpreters}},
volume = {72},
year = {2014}
}
