\chapter{Comparative Study}
The user study to compare teleportation techniques and to provide quantitative figures is detailed in the following chapter. A controlled lab study was performed using the detection methods from the previous chapters in a virtual environment. 

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/participant.PNG}
    \caption{Example of a participant during the study}
    \label{fig:video}
\end{figure}

\section{Study Design}
When looking at the study designs done by Schäfer et al. \cite{Schafer2021} or by Caggianese et al. \cite{Caggianese}, it is apparent that task completion time is an important measurement to rank teleportation methods by. There are some problems with this approach, though. If somebody implemented a teleportation method that takes the user straight to the end of the map where their destination is, it would lead to the quickest task completion times possible. However, this does not make the method easy to control or satisfying to use. Therefore the task completion time was only used as a secondary measure, while measures like usability and task load are more appropriate to compare the methods since they take the users' opinions into account. 

Research Questions:
\begin{enumerate}
    \item How do the different teleportation techniques change the user experience?
    \item What effect do different teleportation techniques have on the way the tasks are executed?
    \item How do the different teleportation techniques affect the subjective workload?
\end{enumerate}

\subsection{Experiment Tasks}
Two tasks were implemented to let participants first gather some experience with VR, teleportation and the gesture that is currently active and then gather insights on the accuracy of the gesture detection and the speed at which the participants can execute a task.

\subsubsection{Task One: Exploration}
The first task is based on a task that would be a realistic use case for a locomotion system. It was conducted using a playful, magical VR environment shown in figure \ref{fig:forestEnv}. 
The participant was tasked to collect an ingredient for a magic potion that could be hidden anywhere on the map. The teleportation system has to be used to search for the ingredient and for it to be brought back to the starting point. Each time, the user received a short in-game tutorial with a picture of the ingredient that should be found with animated hands presenting the gesture and how to use it. This was inspired by the tutorial in the Elixir game \cite{Magnopus}, that can be seen in the background of figure \ref{fig:elixir}.
Each teleport was recorded with the player's position and head gaze direction. The task was specifically designed not to put too much pressure on the participant so they could get to know the gesture and ideally have fun looking around. However, like in a real application, teleportation was still an essential part of the experience, and so small details about the implementation, the detection and the ergonomics would still stand out to the participant. The ingredients were randomly hidden in one out of eight predefined spots, so the user would have to search in a new spot every time.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/forestenv.JPG}
    \caption{Environment to explore in the first task.}
    \label{fig:forestEnv}
\end{figure}

\subsubsection{Task Two: Accuracy}
The second task was based on the work from Bozgeyikli et al. \cite{bozgeyikli}. The original design for the task was followed as closely as possible. There were, however, some changes that needed to be made to adapt it. Like before, the task starts by first showing an animated tutorial again. This time, the user is instructed to quickly teleport between platforms placed on the ground. The platforms are placed in a similar pattern to the original environment by Bozgeyikli et al. and can be seen in figure \ref{fig:accOver}. This time the environment is kept very simple, so the focus is on the task, and so the user would not get distracted by the world. Unlike before, during this task, the task execution time and the accuracy were the main focus. In order to record the start time correctly, the original environment by Bozgeyikli et al. was modified, and a button was placed in the center of the platforms, as shown in figure \ref{fig:accBtn}. The participants were instructed to teleport to the button and press it once they felt ready to start. After the button was activated, it was removed from the environment, and the first platform was highlighted. Like in the original task, the next platform on the ground would light up in a distinctly visual way, as shown in \ref{fig:accPad}, to tell the user where to teleport to. A quick confirmation sound is played when a teleport hits the correct platform to give the user feedback. The player was instructed to stay on the platform for three seconds, after which a different sound was played, and the next platform was highlighted. If a user accidentally teleported off the platform too soon, an error sound was played, and they had to return to the platform and wait for the full three seconds. 

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/accuracy overview.JPG}
    \caption{Overview over Accuracy Task environment}
    \label{fig:accOver}
\end{figure}

\begin{figure}[!htb]
    \begin{subfigure}{0.5\textwidth}
  \centering
        \includegraphics[width=\linewidth]{figures/accuracy button.JPG}
        \caption{Button to start timer}
        \label{fig:accBtn}
    \end{subfigure}%
    \begin{subfigure}{0.5\textwidth}
  \centering
        \includegraphics[width=\linewidth]{figures/accuracy selected pad.JPG}
        \caption{Highlighted platform}
        \label{fig:accPad}
    \end{subfigure}%
\end{figure}

\subsection{Dependent Variables and Operationalization}
To measure the user experience of the locomotion systems for the first research question, the participants filled out a User Experience Questionnaire (UEQ) based on the work of Laugwitz et al. \cite{Laugwitz2008}. The UEQ questionnaire includes 26 scales that are evaluated to produce scores for the six factors attractiveness, efficiency, dependability, perspicuity, stimulation, and novelty. 
A semi-structured interview was conducted after the tasks were completed to get more diverse comments from the participants. Participants were asked to rank the gestures by preference and comfort. Also, they were asked to come up with the advantages and disadvantages of each gesture.

Various information was recorded to get information on how the gesture affects the way the tasks are executed for the second research question. This included all teleport events with information on the destination and the target, the distance travelled, the time they were executed, during which task, by which participant and using which kind of gesture. Also, the participant's movement and head gaze direction was recorded ten times every second.  

Data to answer the third research question was collected using the NASA-TLX questionnaire developed by Hart et al. \cite{Hart1988}.
The NASA-TLX questionnaire consists of six scales for participants to rate their perceived mental demands, physical demands, time demands, performance, effort, and frustration. It was designed to get insights into the participants' perceived workload. It was chosen for this study since it is a standard in the industry and to give information about how performing the tasks using the different gestures systems might result in a difference in the workload. A short version of the NASA-TLX was used to simplify the scoring process that does not include a weighting procedure. According to Bustamante et al. \cite{Bustamante2008}, this is also a valid way to use the test.

\subsection{Participants}
Eight-teen participants (9 female, 9 male) between 19 and 29 years old ($M=23.18,SD=2.58$) completed the study. Only one person considered themselves a VR expert, while everyone else reported very limited or no experience with VR. Two of the participants were left-handed; the 16 other participants had a dominant right hand. 


\subsection{Apparatus}

The room in which the study took place is shown in figure \ref{fig:video}. Its dimensions were 5.70×7.06×2.93 meters with a walkable area of approximately 4.0×7.0 meters.

The tasks were conducted using a Meta Quest 2 with hand-tracking enabled. The headset was connected to the internet and submitted all recorded data to a custom cloud server instance. To be able to monitor and control the task, the server also had a web interface with a number of tools available, shown in figure \ref{fig:settings}. The study operator could control which task is currently running. During testing, it was found that it can be disorienting for the participant to be switched from one scene to another. That is why this control was done manually so the operator can make sure the participant knows what is coming and is not surprised by the scene switch.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/settings.JPG}
    \caption{Settings menu to change scenes and get information about the current state.}
    \label{fig:settings}
\end{figure}

To check if the gesture was recorded correctly, the server provides a 3D visualization of the gesture, as well as a way to delete improperly recorded information, as shown in figures \ref{fig:vis}. This visualization also shows which of the previous recordings are also able to be used to aid the gesture detection step since they are similar to the current recording. They are shown in green in the visualization, while red points represent ignored data points. To be able to find which data points belong to which recording, each can be selected individually and deleted if there is a problem. To be able to find outliers quickly, the average distance to all the other gestures is also displayed in the selection menu. This was very handy for deleting a recording assigned to the wrong gesture state and, therefore, very dissimilar to the other recordings. The recording would then show a large distance from the others and could easily be deleted and rerecorded. All this was very important, so the calibration was consistent and reliable for every participant.

\begin{figure}[!htb]
    \begin{subfigure}{0.5\textwidth}
  \centering
        \includegraphics[width=\linewidth]{figures/point cloud vis.JPG}
        \end{subfigure}%
    \begin{subfigure}{0.5\textwidth}
  \centering
        \includegraphics[width=\linewidth]{figures/point cloud vis2.JPG}
        \end{subfigure}%
        \caption{3D visualization of recorded gesture information for two different states as a point cloud, together with static joints. The green points are selected during the calibration step.}
        \label{fig:vis}
\end{figure}

As shown in figure \ref{fig:map}, the operator was also able to see the position and gaze direction of the participant on a map, as well as the position of the magic potion. This was done in order to be able to give some support to the participant if they required it and to check if the data recording was working. 

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/map.png}
    \caption{Study operators view of the participants position and gaze direction.}
    \label{fig:map}
\end{figure}

To be able to identify what data point belongs to what participant, the server included an interface to manage runs, as shown in figure \ref{fig:runs}. The operator would first start a new run, which generates a random three-letter code. This code was used to be able to match the recording data of one participant anonymously to other data collected during the task, like from the questionnaires. The operator stopped the run after the tasks were completed using the interface and were then able to download and backup the data for each run individually.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/runs.JPG}
    \caption{List of study participants runs.}
    \label{fig:runs}
\end{figure}

All of the commentaries the participants gave and video of the participants were recoded using a Fujifilm X-T4 camera. A sample of the video can be seen in figure \ref{fig:video}.

For the questionnaires, an Apple Ipad Pro was used, as seen in figure \ref{fig:Ipad}. This way, the participants could easily fill out a custom online form consisting of all the questions and the possible answers with their respective scales from positive to negative for all the gestures. This method was also used to collect the demographic information of all the participants. All submissions were collected together with the anonymous unique three-letter code of the participant that was generated to identify which datapoint belongs to which participant. 

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.6\textwidth]{figures/questionaire.png}
    \caption{Example of a questionnaire on the Apple Ipad Pro device.}
    \label{fig:Ipad}
\end{figure}

\subsection{Procedure}
Before the task could start, the participants were informed about teleportation in general and that there is not yet an established way to control teleportation using hand-tracking.

The operator would then give instructions on how the calibration is performed, show the participant how the gesture works and calibrate it together with the participant. The calibration was done in the VR environment shown in figure \ref{fig:calibrationEnv}. The calibration procedure was run three times per state, switching gesture states after each recording. The natural differences between each repetition gave added flexibility since the recordings are all used as a reference during gesture detection. After the three recording steps for each gesture state, the operator would check the recordings if they were recorded and stored correctly. If this was the case, the calibration was done. Otherwise, the recordings were deleted using the 3D visualizer tool, and the step was repeated. This was only the case once. The other recordings were all done correctly and were easy to fix with a quick rerun of the calibration. 

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/calibration env.JPG}
    \caption{Environment used for calibration.}
    \label{fig:calibrationEnv}
\end{figure}

After the calibration, the participants would complete both tasks and fill out the questionnaires. This was not done using the VR headset itself but using a tablet device to give the user some resting time between each run. This procedure was repeated for all three gestures. 
The order of the gestures the participants had to use was fully counterbalanced in order to minimize the learning effect. This means that during the study, it was made sure that three participants would always receive each of the six combinations possible. 
After all tasks and quantitative information were collected, the participants were asked to give some qualitative feedback and share the impressions they got from using the system, as well as rank the gestures. The ranking was both done for overall preference and for how ergonomic the gesture was used.   

\section{Results}
This section presents the results of the study. Several methods were used for the statistical analysis. The Shapiro-Wilk test was used to check whether the data were normally distributed. Since the data were not normally distributed, a non-parametric approach was used for detailed analysis. Friedman ANOVA was used to determine the differences between the three gestures. If this test showed significant differences, further analysis was performed using the Dunn-Bonferroni test. All tests were held to a standard alpha level of 0.05. For the
pairwise comparisons, the Bonferroni correction is required to adjust the alpha level to $(.05/3) \approx .016$.

\subsection{Quantitative Results}
% TODO

\subsubsection{Task Completion Time}
The analysis of the task completion time for the second task shows a statistically significant difference when using the different gesture systems. The time was summed up over all checkpoints, but like in the original study, the first two checkpoints were omitted to give users some time to get used to the task. The analysis using the Friedman's test shows an overall significant difference between the gestures. Additionally, there are significant differences comparing the triangle and palm gesture. The difference between the task completion time using the triangle or index gesture was not significant, with an alpha level of $.67$. Also comparing the index and palm gesture did not lead to a significant result with an alpha level of $.267$.
The task completion times can be seen in figure \ref{fig:taskCompletionTime}, that shows a box plot of the data, with detailed information in table \ref{tbl:taskCompletionTime}. 

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.6\textwidth]{figures/Task Completion Times (in seconds).pdf}
    \caption{Average task completion times for second task in seconds using the respective gestures.}
    \label{fig:taskCompletionTime}
\end{figure}

\begin{table}[]
\centering
\begin{tabular}{lrl}
    \textbf{Gesture} & \textbf{Median} \\
    Index            & $103.2935$               \\
    Palm             & $127.0485$               \\
    Triangle         & $89.294$                
\end{tabular}
\caption{Task completion time statistics}
\label{tbl:taskCompletionTime}
\end{table}


\subsubsection{False-Positive Teleport Activations}
The figure \ref{fig:fpActivations} displays the false-positive teleport activations, with detailed information in table \ref{tbl:fpActivations}. This data was collected in the Accuracy task. If a participant teleported away from a checkpoint during the three second waiting period, this would be logged. That means that this measure only tracks how well the gesture detection is able to detect a neutral position that is not supposed to be teleport activation and not how often the gesture activated in between checkpoints without the users intent to do so. Therefore, the number of accidental teleport is potentially higher. This difference between the gestures overall is statistically significant with an alpha level of $<0.01$. However, when looking at the individual differences it can only be shown that the triangle gesture has the least amount of false-positive activations, while the index and palm gesture do not show a significant difference.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/False Positive Teleport Activations.pdf}
    \caption{False Positive Teleport Activations as a percentage of the overall done teleportations.}
    \label{fig:fpActivations}
\end{figure}

\begin{table}[!h]
\centering
\begin{tabular}{lrl}
    \textbf{Gesture} & \textbf{Median} \\
    Index            & 0,16\%                            \\
    Palm             & 0,14\%                            \\
    Triangle         & 0,07\%                           
\end{tabular}
\caption{False-positive activation statistics, in percent of the overall teleports}
\label{tbl:fpActivations}
\end{table}


\subsubsection{Time Between Teleports}
The time users took between teleports was used as a measurement because, in the second task, users were instructed to teleport between the checkpoints as fast as possible. That resulted in much shorter delays between teleports. The system allows one teleport every 0.7 seconds, but it takes the user some additional time to reorient themselves, pick the next target and execute another teleport. There is a statistically significant difference in the time between teleports that the users took when using the different gesture systems. The pairwise comparisons are also all leading to the same result with a statistically significant difference and an alpha level below the excepted level of $.016$. 

\subsubsection{Teleport Distances}
As seen in figures \ref{fig:dist1} and \ref{fig:dist2}, the teleport distances of all the gestures have only slight differences. 

\begin{figure}[!htb]
    \begin{subfigure}{0.5\textwidth}
  \centering
        \includegraphics[width=\linewidth]{figures/distances.pdf}
        \caption{Teleport distances}
        \label{fig:dist1}
    \end{subfigure}%
    \begin{subfigure}{0.5\textwidth}
  \centering
        \includegraphics[width=\linewidth]{figures/distances2.pdf}
        \caption{Teleport distances}
        \label{fig:dist2}
    \end{subfigure}%
\end{figure}

\subsubsection{Questionnaires}
Both overall scores of NASA-TLX and the UEQ questionnaire do not lead to statistically significant findings. The individual dimensions can be seen in figure \ref{fig:ueqDimensions}. They do not consistently favour a gesture or display a visual pattern of some sort. This result is somewhat surprising since the quantitative results reliably favour the triangle gesture. Comparing the individual dimensions pairwise leads to a significant result for the dependability scores. They are shown separately using in figure \ref{fig:ueqDependability}, with the NASA-TLX scores in \ref{fig:tlx}. 

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/UEQ Scores.pdf}
    \caption{UEQ scores of all dimensions}
    \label{fig:ueqDimensions}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/ueq dependability.pdf}
    \caption{UEQ dependability scores}
    \label{fig:ueqDependability}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/NASA-TLX.pdf}
    \caption{NASA-TLX scores}
    \label{fig:tlx}
\end{figure}

\subsubsection{Ranking by Preference and Ergonomics}
The participants were instructed to come up with two rankings of the gestures. The first was to rank them by individual preference and then by how ergonomic they were to use. Fractional ranking was used for both to correct for participants assigning multiple gestures the same rank. The results are very mixed and the participants can not seem to agree on a favorite or an ergonomic gesture. While the triangle gesture has the best scores on average, it is only by a slight margin with a highly insignificant result ($\alpha > 0.7$) for both rankings. As seen in figures \ref{fig:rankinghisto_index} to \ref{fig:rankinghisto_triangle}, the two rankings do not always align. There seems to be some correlation but there are notable exceptions. For example the palm gesture that seven participants reported to be the best when it comes to ergonomics, is only picked for first place three times, when it comes to preference. 

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Histogram of Index Gesture Rankings.pdf}
    \caption{Binned results of rankings for index gesture.}
    \label{fig:rankinghisto_index}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Histogram of Palm Gesture Rankings.pdf}
    \caption{Binned results of rankings for palm gesture.}
    \label{fig:rankinghisto_palm}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Histogram of Triangle Gesture Rankings.pdf}
    \caption{Binned results of rankings for triangle gesture.}
    \label{fig:rankinghisto_triangle}
\end{figure}



\subsection{Qualitative Results}

\subsubsection{Teleport Trajectories}
The data recorded from the second task is displayed in figure \ref{fig:exp2maps} similarly to the way Bozgeyikli et al. \cite{bozgeyikli} display their results. 

\begin{figure}[!htb]
    \begin{subfigure}{0.32\textwidth}
  \centering
        \includegraphics[width=\linewidth]{figures/index map.png}
        \caption{Index gestures}\label{fig:map_index}
    \end{subfigure}%
    \begin{subfigure}{0.32\textwidth}
  \centering
        \includegraphics[width=\linewidth]{figures/palm map.png}
        \caption{Palm gestures}\label{fig:map_palm}
    \end{subfigure}%
    \begin{subfigure}{0.32\textwidth}
  \centering
        \includegraphics[width=\linewidth]{figures/triangle map.png}
        \caption{Triangle gestures}\label{fig:map_triangle}
    \end{subfigure}%
    \caption{Map of all teleport locations during the Accuracy task using the individual gestures}
    \label{fig:exp2maps}
\end{figure}
    
The visualizations clearly show a difference in how chaotic the teleport targets were placed using the index gesture and how much cleaner they were when the participants used the triangle gesture, with the palm gesture somewhere in the middle. However, none of the gesture-based teleportation techniques produces as clean and efficient routes between the targets as the results shown by Bozgeyikli et al. This indicates that the triangle gesture system is the method that allows users to teleport with the most accuracy and repeatability, with the palm gesture system on second place. It is clear, however, that there is still some room for improvement, even for the triangle gesture system. 

\begin{figure}[!htb]
    \begin{subfigure}{0.32\textwidth}
  \centering
        \includegraphics[width=\linewidth]{figures/index heading.png}
        \caption{Teleport trajectories using the index gestures}\label{fig:map_index2}
    \end{subfigure}%
    \begin{subfigure}{0.32\textwidth}
  \centering
        \includegraphics[width=\linewidth]{figures/palm heading.png}
        \caption{Teleport trajectories using the palm gestures}\label{fig:map_palm2}
    \end{subfigure}%
    \begin{subfigure}{0.32\textwidth}
  \centering
        \includegraphics[width=\linewidth]{figures/triangle heading.png}
        \caption{Teleport trajectories using the triangle gestures}\label{fig:map_triangle2}
    \end{subfigure}%
\end{figure}

The teleport trajectories, seen in figures \ref{fig:map_index2} to \ref{fig:map_triangle2}, show where all of the teleport locations were placed relative to the users' position and head gaze direction. This data was only collected from the accuracy task. This was done because before the task, users were instructed to only teleport quickly from one checkpoint to another, so ideally, this would result in only teleport trajectories straight up. As seen in the visualizations, there is quite a bit of variance. The index gesture produces the most false-positive activations, which contribute to the teleport locations behind the user. Otherwise, most trajectories are going slightly to the left since that would give the user a more ergonomic hand position. The palm gesture results in a much more open spread of trajectories. Users reported the teleport location changing when they closed their hands to confirm the teleport location, which is an explanation for this result. Their trajectories also do not range as far as the other gestures do, which matches participants' comments about strained wrists when trying to teleport far. There are, on the other hand, far fewer teleport locations behind the user, which is consistent with the participants' comments about fewer false-positive activations with the palm gesture compared to the index gesture. The triangle gesture's visualization shows a narrow spread of teleport trajectories, with only a few short teleports behind the user that could also be done on purpose to teleport a step back after traveling too far. This result can therefore be considered the best since it matches the expected pattern the best. 

\subsubsection{Interview}
During the interview, the participants were asked to give commentary on every gesture, both positively and negatively. The opinions the participants expressed are evaluated in the following section. In general, there is not a clearly overall preferred gesture. Some participants reported the opening and closing of the entire hand to form a fist as a confirmation step for the palm gesture to be very tiresome, while others specifically reported this to be the easiest part and that they could do this all day. The users commentary is summarized in the tables \ref{tbl:interview1} to \ref{tbl:interview3}. 

\begin{table}[!h]
\centering
\begin{tabular}{llll}
\hline
Sentiment &
    Index Gesture \\ \hline
positive &
    fast, fun, only little tiring, accurate  \\ \hline
negative &
    \makecell{produces the most false positive activations, \\index finger tips down to meet the thumb while activating, \\susceptable to tracking errors for example when turning hand} \\ \hline
\end{tabular}
\caption{Interview results for index gesture}
\label{tbl:interview1}
\end{table}

\begin{table}[!h]
\centering
\begin{tabular}{llll}
\hline
Sentiment &
    Palm Gesture \\ \hline
positive &
    easy to do, known gesture, natural \\ \hline
negative &
    \makecell{tiring,\\ puts pressure on wrist,\\ difficult to aim acturatly \\ since closing the hand can change the target\\ and it is not easy to hold the hand parallel to the body} \\ \hline
\end{tabular}
\caption{Interview results for palm gesture}
\label{tbl:interview2}
\end{table}

\begin{table}[!h]
\centering
\begin{tabular}{llll}
\hline
Sentiment &
    Triangle Gesture \\ \hline
positive &
    predictable, easy to aim, uses two hands, creative \\ \hline
negative &
    \makecell{difficult to aim far,\\ 2 handed use,\\ some activation problems} \\ \hline
\end{tabular}
\caption{Interview results for triangle gesture}
\label{tbl:interview3}
\end{table}

The comments are coming mainly from the point of frustration with a gesture or the tracking system. So while there are fewer and more negative comments, only a few people reported having a fun and comfortable time using the gestures. The index gesture received mixed feedback with some positive comments that described the gesture as fast and fun to use. However, since it produced the most false-positive activations, it received frustrated comments from the participants about gesture detection. The palm gesture, on the other hand, received mostly feedback concerning the gesture itself and not the tracking. Opening and closing the hand a lot was very tiring for some people. Additionally, activating the gesture would always move the target point at least a little. The triangle gesture received much fewer negative comments, mainly about ergonomic problems that make it difficult to tilt the hands up and that some users prefer a one-handed gesture. There were, however, also participants that preferred two hands since they would make the gesture more distinctly different from other hand gestures. 
