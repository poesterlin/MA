\chapter{Discussion}

The results of the gesture elicitation study show that the changes to the gestures described in 4.2 are intuitive to the user. %TODO: add ref
This is a great result for the further testing.


Developing the gesture detection system was easier than expected and it is working quite well already. It still has limitations though. Since it is using a system of class inheritance to create a teleporter class there is a structure predefined how teleport systems are supposed to work. This might be a limitation for some special types of actions. An example of this would be a system that can convert a gesture to a numeric value, like how far a pinch gesture using the index finger and thumb is closed. This gesture could not be defined using the static recordings of gestures. A workaround storing many individual keyframes that represent each step might work but it would cause other problems. The detection system also has the limitation that a gesture that only requires one-hand needs two sets of stored recordings, one for each hand. A right handed action can currently not be used for a left-handed person that might use the left hand for one-handed gestures intuitively. There is also the limitation that the headset always needs an internet connection to be able to connect to the server that stores the gesture information. However in the future this information could also be stored on the device. In this project an internet connection was required anyway to store statics for later evaluation so it did not make sense to spend time on that for now. The server is otherwise a great addition and allowed the creation of a number of very flexible tools and secure storage of data. Trying out some new technology for the webserver was also a valuable experience. 