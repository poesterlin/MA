\chapter{Implementation Overview}
\label{cha:ImplementationOverview}

A big problem early on in the development of the detection algorithm was how different human hands can be. The detection had to be accurate enough to decide between stored gestures based only one different finger, while staying flexible enough so a user could adjust their hands posture or simply have their own interpretation of the gesture. This turned out to be quite difficult to implement. The final implementation took the following approach to improve the detection accuracy and speed.

A gesture system has multiple assigned states mapped to different actions like aiming and confirming a teleport location. In the current use case, the states are not completely different however. Depending on the gesture system, there is sometimes a lot of overlap between the states. This allows for some optimization in the algorithm. The detection system first compares the joint positions of the joints that are the same in all states. A distance to the stored base version of the gesture system is computed and compared to a threshold to be able to tell if the user is currently presenting a gesture. In order to make the detection more universally accurate to all hand sizes, the system first measures the size of the user's hand. This is achieved by adding up the distance from the wrist joint up to the tip of the middle finger. It was found that this is an accurate enough and very consistent method. The output value of the size calibration allows the detection system to scale the joint positions up or down depending on the users hand size. This improves the accuracy of the first detection step that computes whether a there user is currently presenting a gesture as well as the next step that is used to detect the current gesture state. In the current implementation this can not be done universally for every user however. In some cases the distances between the gesture states are simply too small. This lead to inaccurate detections early on in testing which is frustrating for the user to experiences. Therefor a calibration step was added that would record the users input for every gesture state before it can be used in order to optimize the detection. The recorded ground truth is stored in the system and is used together with previously stored joint positions in order to be able to detect the gesture state accurately. Stored positions that would lead to a wrong detection are also filtered out automatically in this step. This improves the accuracy, keeps the calibration short and provides the user with a high degree of flexibility since they can rely on the calibration input of other, compatible users if they do not execute a gesture change perfectly similar to the calibration run or just naturally shift the way they are gesturing during use.