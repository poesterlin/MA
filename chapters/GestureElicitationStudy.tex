\chapter{Gesture Elicitation Study}
In order to get an overview of what kind of gesture systems can be considered intuitive, a small Gesture Elicitation Study based on the research of Villarreal-Narvaez et al. \cite{elicitation} was performed. This was an essential first step in selecting the gesture systems to conduct further research on, especially since none of the related work that focused on gesture-based locomotion documented a user-driven design approach.

\section{Participants}
The study was conducted with 6 participants, all from the HCI research group and all male. Everyone except one person would consider themselves experienced or experts at VR.

\section{Apparatus}
The study was conducted using a Meta Quest 2 with hand-tracking enabled. The headset was connected to the internet and submitted all recorded data to a custom cloud server instance. To be able to monitor and control the task, the server also had a web interface running on a smartphone via a button, as shown in figure \ref{fig:savebtn}, for recording the current gesture and a 3D visualization that would display the stored gesture as shown in figure \ref{fig:vis2}. The implementation was designed explicitly for low latency between the press of the button and the headset recording a snapshot of the current hand and joint positions. This was done because it would not have been realistic to record everything the participant did with their hands. This way, some information might have been lost. However, because of the simple interface, the operator could look at the participant's hands and determine when to start a recording while pressing the button without looking at their screen. This ensured that the operator had an easy and accurate way to record the data. All of the commentaries the participants gave as well as video of the participants gesturing, were recorded using a Fujifilm X-T4 camera. 

\begin{figure}[!htb]
    \minipage{0.40\textwidth}
        \includegraphics[width=\linewidth]{figures/visualizer.jpg}
        \caption{3D visualization in the browser.}
        \label{fig:vis2}
    \endminipage\hfill
    \minipage{0.40\textwidth}
        \includegraphics[width=\linewidth]{figures/save btn.JPG}
        \caption{Button to store current gesture and joint information.}
        \label{fig:savebtn}
    \endminipage\hfill
\end{figure}

\section{Study Setup}
The participants were instructed to come up with teleportation techniques and explain them in detail. The operator would only mirror the participant's ideas back to them to get as many insights as possible while keeping the participant unbiased. One and two-handed gesture systems were allowed. To understand the limitations of hand-tracking, the subjects were wearing the Oculus Quest device with hand-tracking enabled. It is easy to tell which gesture is tracking well and what is not detected by the tracking cameras. A simple environment with only a plain on the bottom, the skybox and the users tracked virtual hands was used. The environment was created to focus on the hands and the gestures. The headset was connected to a simple web interface over which the study operator could record the current gesture during the study. The recorded position data was stored for detailed analysis after the study. The conversation between the operator and the participants was also recorded on video for analysis. The sessions lasted, on average, about six minutes.

\section{Results}
$33$ different gesture systems were collected from the video and gesture snapshot information, with five systems appearing twice. Nine gesture systems are not usable for the comparison since they are either not strictly teleportation systems or because they can not be compared to other teleportation methods like a system using a minimap or a type of proxy system. Out of the usable $24$ systems, seven use a bimanual approach while $17$ use one hand. Two participants also explicitly called for this trend of one-handed gesture systems that expressed some possible downsides of bimanual systems. The participants reported more physical effort and not being able to carry something in one hand while teleporting as a disadvantage.

The usable gestures can be categorized into three large groups of similar gesture systems. 

The largest group of systems uses at least one hand with the index finger extended as a pointing device. In total, this method was proposed eight times. One gesture is also using an extended middle finger to make the gesture more distinct (figure \ref{fig:index2}), but the targeting system otherwise works the same. The system was proposed to have a confirmation step before the teleport is actually performed six times. According to the participants, this should work by using a "finger gun" type gesture where the thumb is first extended and is then tapped against the base of the index finger to confirm the teleport location, as seen in figure \ref{fig:index}. One user also proposed to gesture an "air tap" with the extended index finger. However, they expressed some concern about the accuracy since moving the finger to confirm could impact the target selection. The second hand was used as a confirmation step but did not influence the targeting system using the pointing hand.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/double index.jpg}
    \caption{Pointing gesture with index and middle finger extended.}
    \label{fig:index2}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{figures/index.jpg}
    \caption{Index finger pointing gesture with two stages.}
    \label{fig:index}
\end{figure}


The second biggest group of gestures was named six times. All gestures use a single, open hand with some kind of confirmation step, as shown in figure \ref{fig:palm2}. Four times closing the hand to a fist was proposed as a confirmation step, with the others quickly tapping the index finger and the thumb together to select the target. Another difference between the systems is the direction the open hand is pointing towards. Four times a ray would start as the average vector of the palm of the hand, once out of the middle finger. One other system proposed to have the palm upwards, with an arc used as the targeting visualization. The arc would curve in the direction of the middle finger and could be manipulated by changing the height of the hand. Holding the hand up high makes the arc go further and would therefore allow teleports over a farther distance.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{figures/palm.jpg}
    \caption{Palm gesture with two stages.}
    \label{fig:palm2}
\end{figure}

A third group is named five times and uses only bimanual systems that use a targeting system where the selection vector is produced by some "rangefinder" the user is looking through. This could be a triangle formed by touching both index fingers and both thumbs together. This was proposed four times. Another proposed option is a "diamond" form formed by touching all fingers to their equivalent finger of the other hand. This forms a hole that can be used to look through. This was proposed twice. All but one system also include a confirmation step that is performed by closing other fingers to a half fist or pinching the hole together.

Other honourable mentions are:
\begin{itemize}
    \item Wrist mounted laser pointer
    \item Pointing using a thumb
    \item OK-Gesture with using the middle finger to point, confirmed when opening the sign
    \item Throwing a teleporting ball to a target
    \item Drawing a circle in the air that will become the new viewport
\end{itemize}

They were all mentioned only once but could also be interesting to investigate.

\section{Discussion}
The results appeared promising for the usability study since most of the intuitively proposed gesture systems by the test subjects are very similar or at least follow the same ideas as the gesture systems found in previous works. There are some notable exceptions, however. Only $4$ out of $24$ gesture systems proposed by the participants did not include an explicit explanation for a confirmation step. This made it apparent that the users would not expect a gesture system based on dwell time as proposed by Sch√§fer et al. \cite{Schafer2021}.